{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "\n",
    "def process_experiment_runs(base_dir):\n",
    "    # Dictionnaire pour stocker les résultats par TS\n",
    "    data_results = {}\n",
    "\n",
    "    # Parcourir tous les sous-dossiers dans ExperimentRuns\n",
    "    for ts_folder in os.listdir(base_dir):\n",
    "        ts_path = os.path.join(base_dir, ts_folder)\n",
    "\n",
    "        # Vérifier si le dossier contient un fichier Zarr\n",
    "        zarr_path = os.path.join(ts_path, \"VoxelSpacing10.000/denoised.zarr\")\n",
    "        if os.path.exists(zarr_path):\n",
    "            print(f\"Traitement de {ts_folder}...\")\n",
    "\n",
    "            # Charger le groupe Zarr\n",
    "            zgroup = zarr.open_group(zarr_path, mode='r')\n",
    "            \n",
    "            # Visualiser l'arborescence\n",
    "            print(f\"Arborescence pour {ts_folder}:\")\n",
    "            print(zgroup.tree())\n",
    "            \n",
    "            # Dictionnaire pour stocker les données de ce TS\n",
    "            ts_data = {}\n",
    "\n",
    "            # Parcourir les sous-groupes (0, 1, 2, ...)\n",
    "            for subgroup_key in zgroup.keys():\n",
    "                subgroup = zgroup[subgroup_key]\n",
    "\n",
    "                # Extraire les métadonnées et les données\n",
    "                ts_data[subgroup_key] = {\n",
    "                    \"attrs\": dict(subgroup.attrs),  # Convertir les métadonnées en dictionnaire\n",
    "                    \"info\": subgroup.info,\n",
    "                    \"data\": subgroup[:],  # Charger les données complètes\n",
    "                }\n",
    "\n",
    "            # Ajouter les données au dictionnaire global\n",
    "            data_results[ts_folder] = ts_data\n",
    "\n",
    "    return data_results\n",
    "\n",
    "\n",
    "# Chemin de base pour ExperimentRuns\n",
    "base_dir = \"data/data/raw/train/static/ExperimentRuns\"\n",
    "\n",
    "# Traiter les tomogrammes\n",
    "all_data = process_experiment_runs(base_dir)\n",
    "\n",
    "# Sauvegarder les résultats ou continuer l'analyse\n",
    "print(\"Traitement terminé. Résumé des données extraites :\")\n",
    "for ts_name, ts_content in all_data.items():\n",
    "    print(f\"- {ts_name}: {len(ts_content)} sous-groupes traités.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TS_5_4'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TS_5_4']['0']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Afficher une coupe z=0 pour chaque résolution\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(all_data['TS_5_4']['0']['data'][0,:,:], cmap='gray')\n",
    "axs[0].set_title(\"Pleine résolution (184, 630, 630)\")\n",
    "axs[1].imshow(all_data['TS_5_4']['1']['data'][0,:,:], cmap='gray')\n",
    "axs[1].set_title(\"Moyenne résolution (92, 315, 315)\")\n",
    "axs[2].imshow(all_data['TS_5_4']['2']['data'][0,:,:], cmap='gray')\n",
    "axs[2].set_title(\"Basse résolution (46, 158, 158)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_targets(base_path):\n",
    "    # Dictionnaire pour stocker les informations de chaque tomogramme\n",
    "    target_data = {}\n",
    "\n",
    "    # Parcourir tous les dossiers dans le chemin de base (numéros de tomogrammes)\n",
    "    for tomogram_folder in os.listdir(base_path):\n",
    "        tomogram_path = os.path.join(base_path, tomogram_folder)\n",
    "\n",
    "        # Vérifier si un dossier \"Picks\" existe dans le tomogramme\n",
    "        picks_path = os.path.join(tomogram_path, \"Picks\")\n",
    "        if not os.path.exists(picks_path):\n",
    "            print(f\"Pas de dossier 'Picks' dans {tomogram_folder}\")\n",
    "            continue\n",
    "\n",
    "        # Parcourir tous les fichiers JSON dans le dossier \"Picks\"\n",
    "        for json_file in os.listdir(picks_path):\n",
    "            if json_file.endswith(\".json\"):\n",
    "                json_path = os.path.join(picks_path, json_file)\n",
    "\n",
    "                # Charger le fichier JSON\n",
    "                with open(json_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # Extraire le nom de la molécule et la localisation des points\n",
    "                molecule_name = data.get(\"pickable_object_name\", \"inconnu\")\n",
    "                points = data.get(\"points\", [])\n",
    "\n",
    "                # Ajouter les informations au dictionnaire\n",
    "                if tomogram_folder not in target_data:\n",
    "                    target_data[tomogram_folder] = {}\n",
    "\n",
    "                # Sauvegarder les données pour chaque molécule dans le tomogramme\n",
    "                target_data[tomogram_folder][molecule_name] = points\n",
    "\n",
    "    return target_data\n",
    "\n",
    "\n",
    "# Chemin de base contenant les dossiers des tomogrammes\n",
    "base_path = \"C:/Users/noemi/Documents/centrale/kaggle/Deep-Learning-Project-CS/data/raw/train/overlay/ExperimentRuns\"\n",
    "\n",
    "# Charger les targets\n",
    "all_targets = load_targets(base_path)\n",
    "\n",
    "# Affichage des données chargées\n",
    "print(\"Résumé des données de targets :\")\n",
    "for tomogram, molecules in all_targets.items():\n",
    "    print(f\"- {tomogram}: {len(molecules)} molécules trouvées\")\n",
    "    for molecule, points in molecules.items():\n",
    "        print(f\"  * {molecule}: {len(points)} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import json\n",
    "\n",
    "def prepare_dataset(image_path, target_path):\n",
    "    \"\"\"\n",
    "    Prépare un dataset associant les données d'images aux targets (protéines et positions).\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Chemin vers le dossier contenant les images Zarr.\n",
    "        target_path (str): Chemin vers le dossier contenant les targets (fichiers JSON).\n",
    "\n",
    "    Returns:\n",
    "        list: Liste de dictionnaires, où chaque élément contient les données d'un tomogramme :\n",
    "            - \"name\": Nom du tomogramme.\n",
    "            - \"images\": Liste des résolutions (volumes 3D).\n",
    "            - \"targets\": Dictionnaire {type_molécule: [positions (x, y, z)]}.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "\n",
    "    # Parcourir les tomogrammes dans le dossier des images\n",
    "    for tomogram_name in os.listdir(image_path):\n",
    "        tomogram_image_path = os.path.join(image_path, tomogram_name, \"VoxelSpacing10.000/denoised.zarr\")\n",
    "        tomogram_target_path = os.path.join(target_path, tomogram_name, \"Picks\")\n",
    "\n",
    "        # Vérifier que les données Zarr et les targets existent\n",
    "        if not os.path.exists(tomogram_image_path):\n",
    "            print(f\"Images non trouvées pour {tomogram_name}, ignoré.\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(tomogram_target_path):\n",
    "            print(f\"Targets non trouvés pour {tomogram_name}, ignoré.\")\n",
    "            continue\n",
    "\n",
    "        # Charger les images (volumes 3D à plusieurs résolutions)\n",
    "        zgroup = zarr.open_group(tomogram_image_path, mode='r')\n",
    "        images = [zgroup[key][:] for key in zgroup.keys()]  # Charger chaque niveau de résolution\n",
    "\n",
    "        # Charger les targets (localisations des particules)\n",
    "        targets = {}\n",
    "        for json_file in os.listdir(tomogram_target_path):\n",
    "            if json_file.endswith(\".json\"):\n",
    "                json_path = os.path.join(tomogram_target_path, json_file)\n",
    "                with open(json_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    molecule_name = data.get(\"pickable_object_name\", \"unknown\")\n",
    "                    points = [\n",
    "                        [point[\"location\"][\"x\"], point[\"location\"][\"y\"], point[\"location\"][\"z\"]]\n",
    "                        for point in data[\"points\"]\n",
    "                    ]\n",
    "                    if molecule_name not in targets:\n",
    "                        targets[molecule_name] = []\n",
    "                    targets[molecule_name].extend(points)\n",
    "\n",
    "        # Ajouter les données du tomogramme au dataset\n",
    "        dataset.append({\n",
    "            \"name\": tomogram_name,\n",
    "            \"images\": images,  # Liste des résolutions\n",
    "            \"targets\": targets  # Localisations des particules par type\n",
    "        })\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins des données\n",
    "image_path = \"data/data/raw/train/static/ExperimentRuns\"\n",
    "target_path = \"data/data/raw/train/overlay/ExperimentRuns\"\n",
    "\n",
    "# Préparer le dataset\n",
    "dataset = prepare_dataset(image_path, target_path)\n",
    "\n",
    "# Exemple : Afficher les données du premier tomogramme\n",
    "print(f\"Nom du tomogramme : {dataset[0]['name']}\")\n",
    "print(f\"Forme de l'image (résolution 1) : {dataset[0]['images'][0].shape}\")\n",
    "print(f\"Targets : {dataset[0]['targets']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def gaussian_filter_3d(volume, sigma):\n",
    "    \"\"\"\n",
    "    Applique un flou gaussien à un volume 3D en traitant chaque slice 2D individuellement.\n",
    "    \n",
    "    Args:\n",
    "        volume (np.array): Volume 3D (z, y, x).\n",
    "        sigma (float): Écart-type pour le noyau gaussien.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Volume 3D flouté.\n",
    "    \"\"\"\n",
    "    blurred_volume = np.zeros_like(volume, dtype=np.float32)\n",
    "    for z in range(volume.shape[0]):  # Itérer sur les slices 2D\n",
    "        blurred_volume[z] = cv2.GaussianBlur(volume[z], (0, 0), sigma)\n",
    "    return blurred_volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmaps(volume_shape, targets, sigma=3, method=\"opencv\"):\n",
    "    \"\"\"\n",
    "    Crée des heatmaps multi-canaux pour les targets avec un flou gaussien.\n",
    "    \n",
    "    Args:\n",
    "        volume_shape (tuple): Dimensions du volume 3D.\n",
    "        targets (dict): Targets {type_molecule: [positions (x, y, z)]}.\n",
    "        sigma (float): Écart-type pour le flou gaussien.\n",
    "        method (str): Méthode pour appliquer le flou (\"opencv\" ou \"numpy\").\n",
    "\n",
    "    Returns:\n",
    "        np.array: Heatmaps multi-canaux de dimensions (num_molecules, *volume_shape).\n",
    "    \"\"\"\n",
    "    molecule_names = list(targets.keys())\n",
    "    heatmaps = np.zeros((len(molecule_names), *volume_shape), dtype=np.float32)\n",
    "\n",
    "    for i, molecule_name in enumerate(molecule_names):\n",
    "        for x, y, z in targets[molecule_name]:\n",
    "            if 0 <= x < volume_shape[2] and 0 <= y < volume_shape[1] and 0 <= z < volume_shape[0]:\n",
    "                heatmaps[i, int(z), int(y), int(x)] += 1\n",
    "\n",
    "        # Appliquer le flou gaussien\n",
    "        if method == \"opencv\":\n",
    "            heatmaps[i] = gaussian_filter_3d(heatmaps[i], sigma=sigma)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Méthode de flou inconnue : choisissez 'opencv' ou 'numpy'.\")\n",
    "\n",
    "    return heatmaps, molecule_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, Model\n",
    "\n",
    "# def unet_3d(input_shape, num_classes):\n",
    "#     \"\"\"\n",
    "#     Implémentation d'un U-Net 3D en TensorFlow/Keras.\n",
    "\n",
    "#     Args:\n",
    "#         input_shape (tuple): Dimensions de l'entrée (z, y, x, c).\n",
    "#         num_classes (int): Nombre de canaux de sortie (types de particules).\n",
    "\n",
    "#     Returns:\n",
    "#         tf.keras.Model: Modèle U-Net 3D.\n",
    "#     \"\"\"\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "#     # Encodeur\n",
    "#     x1 = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "#     x1 = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')(x1)\n",
    "#     p1 = layers.MaxPooling3D(pool_size=2)(x1)\n",
    "\n",
    "#     x2 = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')(p1)\n",
    "#     x2 = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')(x2)\n",
    "#     p2 = layers.MaxPooling3D(pool_size=2)(x2)\n",
    "\n",
    "#     x3 = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same')(p2)\n",
    "#     x3 = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same')(x3)\n",
    "#     p3 = layers.MaxPooling3D(pool_size=2)(x3)\n",
    "\n",
    "#     # Bottleneck\n",
    "#     bn = layers.Conv3D(256, kernel_size=3, activation='relu', padding='same')(p3)\n",
    "#     bn = layers.Conv3D(256, kernel_size=3, activation='relu', padding='same')(bn)\n",
    "\n",
    "#     # Décodeur\n",
    "#     u3 = layers.Conv3DTranspose(128, kernel_size=2, strides=2, padding='same')(bn)\n",
    "#     u3 = layers.concatenate([u3, x3])\n",
    "#     u3 = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same')(u3)\n",
    "#     u3 = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same')(u3)\n",
    "\n",
    "#     u2 = layers.Conv3DTranspose(64, kernel_size=2, strides=2, padding='same')(u3)\n",
    "#     u2 = layers.concatenate([u2, x2])\n",
    "#     u2 = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')(u2)\n",
    "#     u2 = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')(u2)\n",
    "\n",
    "#     u1 = layers.Conv3DTranspose(32, kernel_size=2, strides=2, padding='same')(u2)\n",
    "#     u1 = layers.concatenate([u1, x1])\n",
    "#     u1 = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')(u1)\n",
    "#     u1 = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')(u1)\n",
    "\n",
    "#     # Sortie\n",
    "#     outputs = layers.Conv3D(num_classes, kernel_size=1, activation='sigmoid')(u1)\n",
    "\n",
    "#     return Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        Modèle U-Net 3D pour prédire les heatmaps multi-canaux.\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int): Nombre de canaux d'entrée (1 pour volumes 3D en niveaux de gris).\n",
    "            out_channels (int): Nombre de canaux de sortie (correspondant aux types de particules).\n",
    "        \"\"\"\n",
    "        super(UNet3D, self).__init__()\n",
    "        \n",
    "        # Encoder (réduction de dimension)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder (remonter les dimensions)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv3d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, out_channels, kernel_size=1)  # Une heatmap par type de particule\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TomogramDataset(Dataset):\n",
    "    def __init__(self, dataset, target_size=(64, 128, 128), sigma=3):\n",
    "        \"\"\"\n",
    "        Dataset PyTorch pour les tomogrammes avec heatmaps générées à partir des targets.\n",
    "\n",
    "        Args:\n",
    "            dataset (list): Liste contenant les images et targets.\n",
    "            target_size (tuple): Taille cible des volumes et heatmaps (D, H, W).\n",
    "            sigma (float): Écart-type pour le flou gaussien des heatmaps.\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.target_size = target_size  # Taille cible\n",
    "        for tomogram in dataset:\n",
    "            volume_shape = tomogram[\"images\"][0].shape\n",
    "            heatmaps, _ = create_heatmaps(volume_shape, tomogram[\"targets\"], sigma=sigma)\n",
    "            self.data.append({\"image\": tomogram[\"images\"][0], \"heatmaps\": heatmaps})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        \n",
    "        # Charger et convertir en tenseurs\n",
    "        image = torch.tensor(sample[\"image\"], dtype=torch.float32).unsqueeze(0)  # Ajouter une dimension channel\n",
    "        heatmaps = torch.tensor(sample[\"heatmaps\"], dtype=torch.float32)\n",
    "        \n",
    "        # Redimensionner à la taille cible\n",
    "        image = F.interpolate(image.unsqueeze(0), size=self.target_size, mode='trilinear', align_corners=False).squeeze(0)\n",
    "        heatmaps = F.interpolate(heatmaps.unsqueeze(0), size=self.target_size, mode='trilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        return image, heatmaps\n",
    "\n",
    "# Préparer le DataLoader\n",
    "train_loader = DataLoader(TomogramDataset(dataset, target_size=(64, 128, 128)), batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Vérifie si un GPU est disponible\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU disponible :\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU non disponible. Utilisation du CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# Initialiser le modèle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPUdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')print('Using device:', device)print()\n",
    "#Additional Info when using cudaif device.type == 'cuda':\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print('Memory Usage:')\n",
    "print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet3D(in_channels=1, out_channels=len(dataset[0][\"targets\"])).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, heatmaps in train_loader:\n",
    "        images, heatmaps = images.to(device), heatmaps.to(device)\n",
    "\n",
    "        # Réinitialiser les gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calcul de la perte\n",
    "        loss = criterion(outputs, heatmaps)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimisation\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les poids du modèle\n",
    "model_save_path = \"unet3d_weights.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Modèle sauvegardé dans {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_path = \"unet3d_weights.pth\"\n",
    "model = UNet3D(in_channels=1, out_channels=len(dataset[0][\"targets\"])).to(device)\n",
    "model.load_state_dict(torch.load(model_load_path))\n",
    "print(\"Poids du modèle chargés avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des tomogrammes d'intérêt\n",
    "selected_tomograms = [\"TS_5_4\", \"TS_6_4\", \"TS_69_2\"]\n",
    "\n",
    "# Filtrer le dataset\n",
    "test_dataset = [tomogram for tomogram in dataset if tomogram[\"name\"] in selected_tomograms]\n",
    "\n",
    "# Vérifier les tomogrammes sélectionnés\n",
    "print(f\"Tomogrammes sélectionnés ({len(test_dataset)}): {[t['name'] for t in test_dataset]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un DataLoader pour les tomogrammes sélectionnés\n",
    "test_loader = DataLoader(\n",
    "    TomogramDataset(test_dataset, target_size=(64, 128, 128)),\n",
    "    batch_size=1,  # Une image à la fois pour une meilleure visualisation\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle\n",
    "model = UNet3D(in_channels=1, out_channels=6).to(device)\n",
    "model.load_state_dict(torch.load(\"unet3d_weights.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Tester sur les tomogrammes sélectionnés\n",
    "for idx, (images, heatmaps) in enumerate(test_loader):\n",
    "    images = images.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Obtenir les prédictions\n",
    "        predictions = model(images)\n",
    "    \n",
    "    # Convertir les prédictions en numpy pour visualisation ou post-traitement\n",
    "    predictions_np = predictions.cpu().numpy()\n",
    "    print(f\"Prédictions pour le tomogramme {test_dataset[idx]['name']}:\")\n",
    "    print(predictions_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[0]['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_metrics(predictions, targets, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcule les métriques IoU, Dice et MSE entre les prédictions et les targets.\n",
    "\n",
    "    Args:\n",
    "        predictions (torch.Tensor): Tenseur des prédictions.\n",
    "        targets (torch.Tensor): Tenseur des targets.\n",
    "        threshold (float): Seuil pour binariser les prédictions.\n",
    "\n",
    "    Returns:\n",
    "        dict: Métriques calculées.\n",
    "    \"\"\"\n",
    "    # Binariser les prédictions\n",
    "    binary_preds = (predictions > threshold).float()\n",
    "    binary_targets = (targets > threshold).float()\n",
    "    \n",
    "    # Intersection et union pour IoU\n",
    "    intersection = (binary_preds * binary_targets).sum()\n",
    "    union = (binary_preds + binary_targets).clamp(0, 1).sum()\n",
    "    iou = intersection / (union + 1e-8)  # Ajouter un epsilon pour éviter la division par zéro\n",
    "\n",
    "    # Dice coefficient\n",
    "    dice = (2 * intersection) / (binary_preds.sum() + binary_targets.sum() + 1e-8)\n",
    "\n",
    "    # MSE\n",
    "    mse = ((predictions - targets) ** 2).mean()\n",
    "\n",
    "    return {\"IoU\": iou.item(), \"Dice\": dice.item(), \"MSE\": mse.item()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résultats des métriques pour chaque tomogramme\n",
    "results = []\n",
    "\n",
    "model.eval()\n",
    "for idx, (images, targets) in enumerate(test_loader):\n",
    "    images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Prédictions\n",
    "        predictions = model(images)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calcul des métriques\n",
    "    metrics = compute_metrics(predictions[0], targets[0])  # Comparer une instance\n",
    "    metrics[\"name\"] = test_dataset[idx][\"name\"]\n",
    "    results.append(metrics)\n",
    "\n",
    "# Afficher les résultats pour chaque tomogramme\n",
    "for result in results:\n",
    "    print(f\"Tomogramme: {result['name']}, IoU: {result['IoU']:.4f}, Dice: {result['Dice']:.4f}, MSE: {result['MSE']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sélectionner un échantillon pour la visualisation\n",
    "sample_idx = 0  # Premier échantillon dans le test_loader\n",
    "sample_name = test_dataset[sample_idx][\"name\"]\n",
    "\n",
    "# Charger l'image, les prédictions et les labels\n",
    "images, targets = next(iter(test_loader))\n",
    "images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(images)\n",
    "\n",
    "# Convertir en numpy\n",
    "image_np = images[0, 0].cpu().numpy()  # Image 3D\n",
    "predictions_np = predictions[0].cpu().numpy()  # Prédictions 3D multi-canaux\n",
    "targets_np = targets[0].cpu().numpy()  # Labels 3D multi-canaux\n",
    "\n",
    "# Sélectionner la coupe médiane en Z\n",
    "z_slice = image_np.shape[0] // 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Image originale\n",
    "axes[0].imshow(image_np[z_slice], cmap=\"gray\")\n",
    "axes[0].set_title(f\"Image originale - {sample_name}\")\n",
    "\n",
    "# Labels réels en superposition (coloré par type de molécule)\n",
    "target_overlay = np.zeros((*targets_np.shape[1:], 3))  # Image couleur\n",
    "for i in range(targets_np.shape[0]):  # Parcourir les canaux (molécules)\n",
    "    target_overlay[..., i % 3] += targets_np[i, z_slice]  # Ajouter au canal R, G ou B\n",
    "\n",
    "axes[1].imshow(image_np[z_slice], cmap=\"gray\")\n",
    "axes[1].imshow(target_overlay, alpha=0.5)  # Superposition semi-transparente\n",
    "axes[1].set_title(\"Labels réels\")\n",
    "\n",
    "# Prédictions en superposition (coloré par type de molécule)\n",
    "prediction_overlay = np.zeros((*predictions_np.shape[1:], 3))  # Image couleur\n",
    "for i in range(predictions_np.shape[0]):\n",
    "    prediction_overlay[..., i % 3] += predictions_np[i, z_slice]\n",
    "\n",
    "axes[2].imshow(image_np[z_slice], cmap=\"gray\")\n",
    "axes[2].imshow(prediction_overlay, alpha=0.5)\n",
    "axes[2].set_title(\"Prédictions\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
