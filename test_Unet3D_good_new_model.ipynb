{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "from config import DATA_DIR, TARGET_DIR\n",
    "import numpy as np\n",
    "\n",
    "def process_experiment_runs(base_dir):\n",
    "    data_results = {}\n",
    "\n",
    "    for ts_folder in os.listdir(base_dir):\n",
    "        ts_path = os.path.join(base_dir, ts_folder)\n",
    "\n",
    "        zarr_path = os.path.join(ts_path, \"VoxelSpacing10.000/denoised.zarr\")\n",
    "        if os.path.exists(zarr_path):\n",
    "            print(f\"Traitement de {ts_folder}...\")\n",
    "\n",
    "            zgroup = zarr.open_group(zarr_path, mode='r')\n",
    "\n",
    "            print(f\"Arborescence pour {ts_folder}:\")\n",
    "            print(zgroup.tree())\n",
    "\n",
    "            ts_data = {}\n",
    "\n",
    "            for subgroup_key in zgroup.keys():\n",
    "                subgroup = zgroup[subgroup_key]\n",
    "\n",
    "                ts_data[subgroup_key] = {\n",
    "                    \"attrs\": dict(subgroup.attrs),\n",
    "                    \"info\": subgroup.info,\n",
    "                    \"data\": subgroup[:],\n",
    "                }\n",
    "\n",
    "            data_results[ts_folder] = ts_data\n",
    "\n",
    "    return data_results\n",
    "\n",
    "all_data = process_experiment_runs(DATA_DIR)\n",
    "\n",
    "print(\"Traitement terminé. Résumé des données extraites :\")\n",
    "for ts_name, ts_content in all_data.items():\n",
    "    print(f\"- {ts_name}: {len(ts_content)} sous-groupes traités.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(all_data['TS_5_4']['0']['data'][0,:,:], cmap='gray')\n",
    "axs[0].set_title(\"Pleine résolution (184, 630, 630)\")\n",
    "axs[1].imshow(all_data['TS_5_4']['1']['data'][0,:,:], cmap='gray')\n",
    "axs[1].set_title(\"Moyenne résolution (92, 315, 315)\")\n",
    "axs[2].imshow(all_data['TS_5_4']['2']['data'][0,:,:], cmap='gray')\n",
    "axs[2].set_title(\"Basse résolution (46, 158, 158)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_targets(base_path):\n",
    "    target_data = {}\n",
    "\n",
    "    for tomogram_folder in os.listdir(base_path):\n",
    "        tomogram_path = os.path.join(base_path, tomogram_folder)\n",
    "\n",
    "        picks_path = os.path.join(tomogram_path, \"Picks\")\n",
    "        if not os.path.exists(picks_path):\n",
    "            print(f\"Pas de dossier 'Picks' dans {tomogram_folder}\")\n",
    "            continue\n",
    "\n",
    "        for json_file in os.listdir(picks_path):\n",
    "            if json_file.endswith(\".json\"):\n",
    "                json_path = os.path.join(picks_path, json_file)\n",
    "\n",
    "                with open(json_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                molecule_name = data.get(\"pickable_object_name\", \"inconnu\")\n",
    "                points = data.get(\"points\", [])\n",
    "\n",
    "                if tomogram_folder not in target_data:\n",
    "                    target_data[tomogram_folder] = {}\n",
    "\n",
    "                target_data[tomogram_folder][molecule_name] = points\n",
    "\n",
    "    return target_data\n",
    "\n",
    "all_targets = load_targets(TARGET_DIR)\n",
    "\n",
    "print(\"Résumé des données de targets :\")\n",
    "for tomogram, molecules in all_targets.items():\n",
    "    print(f\"- {tomogram}: {len(molecules)} molécules trouvées\")\n",
    "    for molecule, points in molecules.items():\n",
    "        print(f\"  * {molecule}: {len(points)} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# --- Histogramme global ---\n",
    "global_counts = {}\n",
    "for tomogram, molecules in all_targets.items():\n",
    "    for molecule, points in molecules.items():\n",
    "        global_counts[molecule] = global_counts.get(molecule, 0) + len(points)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(global_counts.keys(), global_counts.values(), color='skyblue')\n",
    "plt.xlabel(\"Type de protéine\")\n",
    "plt.ylabel(\"Nombre d'exemplaires\")\n",
    "plt.title(\"Histogramme global du nombre d'exemplaires de protéines\")\n",
    "plt.show()\n",
    "\n",
    "num_tomograms = len(all_targets)\n",
    "\n",
    "cols = 2\n",
    "rows = math.ceil(num_tomograms / cols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*6, rows*4), squeeze=False)\n",
    "\n",
    "tomogram_names = list(all_targets.keys())\n",
    "for idx, tomogram in enumerate(tomogram_names):\n",
    "    row = idx // cols\n",
    "    col = idx % cols\n",
    "    ax = axes[row][col]\n",
    "    \n",
    "    counts = {molecule: len(points) for molecule, points in all_targets[tomogram].items()}\n",
    "    \n",
    "    ax.bar(counts.keys(), counts.values(), color='lightgreen')\n",
    "    ax.set_title(tomogram)\n",
    "    ax.set_xlabel(\"Protéine\")\n",
    "    ax.set_ylabel(\"Nombre d'exemplaires\")\n",
    "    ax.tick_params(axis='x', labelrotation=45, labelsize=8)\n",
    "\n",
    "total_plots = rows * cols\n",
    "if num_tomograms < total_plots:\n",
    "    for idx in range(num_tomograms, total_plots):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        fig.delaxes(axes[row][col])\n",
    "\n",
    "plt.suptitle(\"Histogrammes par tomogramme du nombre d'exemplaires de protéines\", fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import json\n",
    "\n",
    "def prepare_dataset(image_path, target_path):\n",
    "    \"\"\"\n",
    "    Prépare un dataset associant les données d'images aux targets (protéines et positions).\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Chemin vers le dossier contenant les images Zarr.\n",
    "        target_path (str): Chemin vers le dossier contenant les targets (fichiers JSON).\n",
    "\n",
    "    Returns:\n",
    "        list: Liste de dictionnaires, où chaque élément contient les données d'un tomogramme :\n",
    "            - \"name\": Nom du tomogramme.\n",
    "            - \"images\": Liste des résolutions (volumes 3D).\n",
    "            - \"targets\": Dictionnaire {type_molécule: [positions (x, y, z)]}.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "\n",
    "    for tomogram_name in os.listdir(image_path):\n",
    "        tomogram_image_path = os.path.join(image_path, tomogram_name, \"VoxelSpacing10.000/denoised.zarr\")\n",
    "        tomogram_target_path = os.path.join(target_path, tomogram_name, \"Picks\")\n",
    "\n",
    "        if not os.path.exists(tomogram_image_path):\n",
    "            print(f\"Images non trouvées pour {tomogram_name}, ignoré.\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(tomogram_target_path):\n",
    "            print(f\"Targets non trouvés pour {tomogram_name}, ignoré.\")\n",
    "            continue\n",
    "\n",
    "        zgroup = zarr.open_group(tomogram_image_path, mode='r')\n",
    "        sorted_keys = sorted(zgroup.keys(), key=lambda k: np.prod(zgroup[k].shape), reverse=True)\n",
    "        images = [zgroup[key][:] for key in sorted_keys]\n",
    "\n",
    "        targets = {}\n",
    "        for json_file in os.listdir(tomogram_target_path):\n",
    "            if json_file.endswith(\".json\"):\n",
    "                json_path = os.path.join(tomogram_target_path, json_file)\n",
    "                with open(json_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    molecule_name = data.get(\"pickable_object_name\", \"unknown\")\n",
    "                    points = [\n",
    "                        [point[\"location\"][\"x\"], point[\"location\"][\"y\"], point[\"location\"][\"z\"]]\n",
    "                        for point in data[\"points\"]\n",
    "                    ]\n",
    "                    if molecule_name not in targets:\n",
    "                        targets[molecule_name] = []\n",
    "                    targets[molecule_name].extend(points)\n",
    "\n",
    "        dataset.append({\n",
    "            \"name\": tomogram_name,\n",
    "            \"images\": images,\n",
    "            \"targets\": targets\n",
    "        })\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def print_shapes(dataset):\n",
    "    for tomogram in dataset:\n",
    "        print(f\"Tomogramme {tomogram['name']}:\")\n",
    "        for i, image in enumerate(tomogram['images']):\n",
    "            print(f\"  - Résolution {i}: {image.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(DATA_DIR, TARGET_DIR)\n",
    "\n",
    "print_shapes(dataset)\n",
    "\n",
    "print(f\"Nom du tomogramme : {dataset[0]['name']}\")\n",
    "print(f\"Forme de l'image (résolution 1) : {dataset[0]['images'][0].shape}\")\n",
    "print(f\"Targets : {dataset[0]['targets']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "voxel_size = 10\n",
    "\n",
    "tomogram_folder = 'TS_5_4'\n",
    "resolution_group = '0'\n",
    "slice_index = 90\n",
    "\n",
    "tomogram_volume = all_data[tomogram_folder][resolution_group]['data']\n",
    "image_slice = tomogram_volume[slice_index, :, :]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image_slice, cmap='gray')\n",
    "plt.title(f\"Tomogramme {tomogram_folder} - Coupe Z={slice_index}\")\n",
    "\n",
    "if tomogram_folder in all_targets:\n",
    "    molecules = all_targets[tomogram_folder]\n",
    "\n",
    "    legend_entries = {}\n",
    "\n",
    "    for molecule, points in molecules.items():\n",
    "        for point in points:\n",
    "            x = point[\"location\"][\"x\"] / voxel_size\n",
    "            y = point[\"location\"][\"y\"] / voxel_size\n",
    "            z = point[\"location\"][\"z\"] / voxel_size\n",
    "\n",
    "            if abs(z - slice_index) < 3:\n",
    "                sc = plt.scatter(x, y, s=20)\n",
    "                if molecule not in legend_entries:\n",
    "                    legend_entries[molecule] = sc\n",
    "\n",
    "    if legend_entries:\n",
    "        plt.legend(legend_entries.values(), legend_entries.keys(), loc='upper right')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "voxel_size = 40\n",
    "tomogram_folder = 'TS_5_4'\n",
    "resolution_group = '2'\n",
    "slice_index = 15\n",
    "\n",
    "tomogram_volume = all_data[tomogram_folder][resolution_group]['data']\n",
    "image_slice = tomogram_volume[slice_index, :, :]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image_slice, cmap='gray')\n",
    "plt.title(f\"Tomogramme {tomogram_folder} - Résolution 2 - Slice Z={slice_index}\")\n",
    "\n",
    "if tomogram_folder in all_targets:\n",
    "    molecules = all_targets[tomogram_folder]\n",
    "\n",
    "    legend_entries = {}\n",
    "\n",
    "    for molecule, points in molecules.items():\n",
    "        for point in points:\n",
    "            x = point[\"location\"][\"x\"] / voxel_size\n",
    "            y = point[\"location\"][\"y\"] / voxel_size\n",
    "            z = point[\"location\"][\"z\"] / voxel_size\n",
    "\n",
    "            if abs(z - slice_index) < 0.75:\n",
    "                sc = plt.scatter(x, y, s=20)\n",
    "                if molecule not in legend_entries:\n",
    "                    legend_entries[molecule] = sc\n",
    "\n",
    "    if legend_entries:\n",
    "        plt.legend(legend_entries.values(), legend_entries.keys(), loc='upper right')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "voxel_size = 40 \n",
    "\n",
    "class_mapping = {\n",
    "    \"background\": 0,\n",
    "    \"apo-ferritin\": 1,\n",
    "    \"beta-amylase\": 2,\n",
    "    \"beta-galactosidase\": 3,\n",
    "    \"ribosome\": 4,\n",
    "    \"thyroglobulin\": 5,\n",
    "    \"virus-like-particle\": 6\n",
    "}\n",
    "\n",
    "class_labels = {\n",
    "    0: \"background\",\n",
    "    1: \"apo-ferritin\",\n",
    "    2: \"beta-amylase\",\n",
    "    3: \"beta-galactosidase\",\n",
    "    4: \"ribosome\",\n",
    "    5: \"thyroglobulin\",\n",
    "    6: \"virus-like-particle\",\n",
    "}\n",
    "\n",
    "def generate_mask(volume_shape, targets, voxel_size, class_mapping, sphere_radius=2):\n",
    "    \"\"\"\n",
    "    Crée un masque de segmentation (de dimensions volume_shape) à partir des targets.\n",
    "    Pour chaque point, on convertit la position physique en indice voxel et on dessine\n",
    "    une petite sphère (de rayon sphere_radius voxels) avec la classe correspondante.\n",
    "    \n",
    "    Args:\n",
    "        volume_shape (tuple): Dimensions du volume (Z, Y, X).\n",
    "        targets (dict): Dictionnaire des targets avec pour chaque molécule une liste de points.\n",
    "        voxel_size (float): Facteur de conversion des coordonnées physiques en indices voxels.\n",
    "        class_mapping (dict): Mapping de la molécule vers l'indice de classe (0 pour le fond, >0 pour les particules).\n",
    "        sphere_radius (int): Rayon de la sphère (en voxels) à dessiner autour de chaque point.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Masque de segmentation de dimensions volume_shape.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(volume_shape, dtype=np.uint8)  # Fond = 0\n",
    "    for molecule, points in targets.items():\n",
    "        if molecule not in class_mapping:\n",
    "            continue\n",
    "        class_idx = class_mapping[molecule]\n",
    "        for point in points:\n",
    "            # Si le point est un dictionnaire avec la clé \"location\", on l'utilise\n",
    "            if isinstance(point, dict) and \"location\" in point:\n",
    "                x_coord = point[\"location\"][\"x\"]\n",
    "                y_coord = point[\"location\"][\"y\"]\n",
    "                z_coord = point[\"location\"][\"z\"]\n",
    "            else:\n",
    "                # Sinon, on suppose que le point est une liste/tuple de coordonnées [x, y, z]\n",
    "                x_coord, y_coord, z_coord = point\n",
    "            \n",
    "            x_center = int(round(x_coord / voxel_size))\n",
    "            y_center = int(round(y_coord / voxel_size))\n",
    "            z_center = int(round(z_coord / voxel_size))\n",
    "            \n",
    "            # Dessiner une petite sphère autour du point\n",
    "            for dz in range(-sphere_radius, sphere_radius + 1):\n",
    "                for dy in range(-sphere_radius, sphere_radius + 1):\n",
    "                    for dx in range(-sphere_radius, sphere_radius + 1):\n",
    "                        if dx**2 + dy**2 + dz**2 <= sphere_radius**2:\n",
    "                            z_idx = z_center + dz\n",
    "                            y_idx = y_center + dy\n",
    "                            x_idx = x_center + dx\n",
    "                            if (0 <= z_idx < volume_shape[0] and\n",
    "                                0 <= y_idx < volume_shape[1] and\n",
    "                                0 <= x_idx < volume_shape[2]):\n",
    "                                mask[z_idx, y_idx, x_idx] = class_idx\n",
    "    return mask\n",
    "\n",
    "def extract_grid_patches(volume, mask, num_cubes_axis):\n",
    "    \"\"\"\n",
    "    Extrait tous les patches qui couvrent entièrement le volume en divisant chaque dimension en num_cubes_axis segments.\n",
    "    On suppose que le volume est exactement divisible par num_cubes_axis sur chaque axe.\n",
    "    \n",
    "    Args:\n",
    "        volume (ndarray): Volume 3D d'entrée, de forme (Z, Y, X).\n",
    "        mask (ndarray): Masque associé, de même forme.\n",
    "        num_cubes_axis (int): Nombre de segments (patchs) par axe (exemple : 4 donnera 4x4x4 = 64 patches).\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (patches_img, patches_mask) \n",
    "               - patches_img : liste de patches d'image.\n",
    "               - patches_mask : liste de patches de masque.\n",
    "    \"\"\"\n",
    "    z_dim, y_dim, x_dim = volume.shape\n",
    "    patch_size_z = z_dim // num_cubes_axis\n",
    "    patch_size_y = y_dim // num_cubes_axis\n",
    "    patch_size_x = x_dim // num_cubes_axis\n",
    "    \n",
    "    patches_img = []\n",
    "    patches_mask = []\n",
    "    \n",
    "    for i in range(num_cubes_axis):\n",
    "        for j in range(num_cubes_axis):\n",
    "            for k in range(num_cubes_axis):\n",
    "                z0 = i * patch_size_z\n",
    "                y0 = j * patch_size_y\n",
    "                x0 = k * patch_size_x\n",
    "                patch_img = volume[z0:z0+patch_size_z, y0:y0+patch_size_y, x0:x0+patch_size_x]\n",
    "                patch_mask = mask[z0:z0+patch_size_z, y0:y0+patch_size_y, x0:x0+patch_size_x]\n",
    "                patches_img.append(patch_img)\n",
    "                patches_mask.append(patch_mask)\n",
    "    \n",
    "    return patches_img, patches_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "Y_train_list = []\n",
    "\n",
    "num_cubes_axis = 2\n",
    "\n",
    "for tomogram in dataset:\n",
    "    volume = tomogram[\"images\"][2]\n",
    "    mask_full = generate_mask(volume.shape, tomogram[\"targets\"], voxel_size, class_mapping)\n",
    "    print(f\"Tomogramme {tomogram['name']} volume: {volume.shape}, masque: {mask_full.shape}\")\n",
    "\n",
    "    patches_img, patches_mask = extract_grid_patches(volume, mask_full, num_cubes_axis)\n",
    "\n",
    "    for patch_img, patch_mask in zip(patches_img, patches_mask):\n",
    "        patch_img = patch_img[..., np.newaxis]\n",
    "        X_train_list.append(patch_img)\n",
    "        Y_train_list.append(patch_mask)\n",
    "\n",
    "X_train = np.array(X_train_list, dtype=np.float32)\n",
    "Y_train_int = np.array(Y_train_list, dtype=np.uint8)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train_int shape:\", Y_train_int.shape)\n",
    "\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train_int, num_classes=7)\n",
    "print(\"Y_train shape (one-hot):\", Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "indices_with_protein = np.where((Y_train_int > 0).any(axis=(1, 2, 3)))[0]\n",
    "\n",
    "X_train_balanced = X_train\n",
    "Y_train_int_balanced = Y_train_int\n",
    "\n",
    "unique_classes, counts = np.unique(Y_train_int_balanced, return_counts=True)\n",
    "\n",
    "total_voxels = np.sum(counts)\n",
    "percentages = (counts / total_voxels) * 100\n",
    "\n",
    "df_percentages = pd.DataFrame({\n",
    "    \"Classe\": [class_labels.get(int(cls), f\"Classe {cls}\") for cls in unique_classes],\n",
    "    \"Nombre de Voxels\": counts,\n",
    "    \"Pourcentage (%)\": percentages\n",
    "})\n",
    "\n",
    "print(df_percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def generate_colored_mask(volume_shape, targets, voxel_size, class_mapping, slice_index, sphere_radius=3, colors=None):\n",
    "    mask_slice = np.zeros((volume_shape[1], volume_shape[2], 3), dtype=np.uint8)\n",
    "\n",
    "    for molecule, points in targets.items():\n",
    "        if molecule not in class_mapping:\n",
    "            continue\n",
    "        color = colors.get(molecule, (255, 255, 255))\n",
    "\n",
    "        for point in points:\n",
    "            x_coord = int(round(point[\"location\"][\"x\"] / voxel_size))\n",
    "            y_coord = int(round(point[\"location\"][\"y\"] / voxel_size))\n",
    "            z_coord = int(round(point[\"location\"][\"z\"] / voxel_size))\n",
    "\n",
    "            if z_coord == slice_index:\n",
    "                for dy in range(-sphere_radius, sphere_radius + 1):\n",
    "                    for dx in range(-sphere_radius, sphere_radius + 1):\n",
    "                        if dx**2 + dy**2 <= sphere_radius**2:\n",
    "                            y_idx = y_coord + dy\n",
    "                            x_idx = x_coord + dx\n",
    "                            if 0 <= y_idx < volume_shape[1] and 0 <= x_idx < volume_shape[2]:\n",
    "                                mask_slice[y_idx, x_idx] = color\n",
    "\n",
    "    return mask_slice\n",
    "\n",
    "def display_tomogram_and_target(all_data, all_targets, tomogram_folder, resolution_group, slice_index, voxel_size, class_mapping, sphere_radius=3):\n",
    "    volume = all_data[tomogram_folder][resolution_group]['data']\n",
    "    image_slice = volume[slice_index, :, :]\n",
    "\n",
    "    targets_filtered = {}\n",
    "    for molecule, points in all_targets.get(tomogram_folder, {}).items():\n",
    "        filtered_points = [p for p in points if round(p[\"location\"][\"z\"] / voxel_size) == slice_index]\n",
    "        if filtered_points:\n",
    "            targets_filtered[molecule] = filtered_points\n",
    "\n",
    "    colors = {\n",
    "        \"apo-ferritin\": (255, 0, 0),\n",
    "        \"beta-amylase\": (0, 0, 255),\n",
    "        \"ribosome\": (128, 0, 128),\n",
    "        \"thyroglobulin\": (255, 165, 0),\n",
    "        \"virus-like-particle\": (0, 255, 255),\n",
    "        \"beta-galactosidase\": (0, 255, 0)\n",
    "    }\n",
    "\n",
    "    mask_colored = generate_colored_mask(volume.shape, targets_filtered, voxel_size, class_mapping, slice_index, sphere_radius, colors)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    axs[0].imshow(image_slice, cmap='gray')\n",
    "    axs[0].set_title(f\"Tomogramme {tomogram_folder} - Slice Z={slice_index}\", fontsize=25)\n",
    "\n",
    "    legend_entries = {}\n",
    "    for molecule, points in targets_filtered.items():\n",
    "        color = np.array(colors.get(molecule, (255, 255, 255))) / 255\n",
    "        for point in points:\n",
    "            x = point[\"location\"][\"x\"] / voxel_size\n",
    "            y = point[\"location\"][\"y\"] / voxel_size\n",
    "            circle = plt.Circle((x, y), radius=sphere_radius, color=color, fill=False, linewidth=2)\n",
    "            axs[0].add_patch(circle)\n",
    "\n",
    "            if molecule not in legend_entries:\n",
    "                legend_entries[molecule] = plt.Line2D([0], [0], marker='o', color=color, markersize=15, linestyle='', label=molecule)\n",
    "\n",
    "    if legend_entries:\n",
    "        axs[0].legend(handles=legend_entries.values(), loc='upper right', fontsize=20)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(mask_colored)\n",
    "    axs[1].set_title(f\"Masque Target {tomogram_folder} - Slice Z={slice_index}\", fontsize=25)\n",
    "\n",
    "    legend_entries_mask = [\n",
    "        plt.Line2D([0], [0], marker='s', color=np.array(color)/255, markersize=20, linestyle='', label=molecule)\n",
    "        for molecule, color in colors.items() if molecule in targets_filtered\n",
    "    ]\n",
    "\n",
    "    if legend_entries_mask:\n",
    "        axs[1].legend(handles=legend_entries_mask, loc='upper right', fontsize=20)\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "voxel_size = 40\n",
    "tomogram_folder = 'TS_5_4'\n",
    "resolution_group = '2'\n",
    "slice_index = 23\n",
    "\n",
    "display_tomogram_and_target(all_data, all_targets, tomogram_folder, resolution_group, slice_index, voxel_size, class_mapping, sphere_radius=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def visualize_augmented_samples(X_aug, Y_aug, num_samples=5):\n",
    "    \"\"\"Affiche plusieurs exemples d'images augmentées avec leurs masques.\"\"\"\n",
    "    indices = np.random.choice(len(X_aug), num_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, num_samples * 5))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image = X_aug[idx].squeeze()\n",
    "        mask = np.argmax(Y_aug[idx], axis=-1)\n",
    "\n",
    "        slice_idx = random.randint(0, image.shape[0] - 1)\n",
    "\n",
    "        axes[i, 0].imshow(image[slice_idx, :, :], cmap='gray')\n",
    "        axes[i, 0].set_title(f\"Image Augmentée (Slice Z={slice_idx})\")\n",
    "\n",
    "        axes[i, 1].imshow(mask[slice_idx, :, :], cmap='jet')\n",
    "        axes[i, 1].set_title(f\"Masque Associé (Slice Z={slice_idx})\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_augmented_samples(X_train, Y_train, num_samples=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
    "    X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(\n",
    "    X_temp, Y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Afficher les tailles des splits\n",
    "print(f\"Train set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n",
    "print(f\"Train set: {Y_train.shape}, Validation set: {Y_val.shape}, Test set: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protein_accuracy(y_true, y_pred):\n",
    "    y_true_labels = tf.argmax(y_true, axis=-1)\n",
    "    y_pred_labels = tf.argmax(y_pred, axis=-1)\n",
    "    mask = tf.not_equal(y_true_labels, 0)\n",
    "    correct = tf.equal(y_true_labels, y_pred_labels)\n",
    "    correct_masked = tf.boolean_mask(correct, mask)\n",
    "\n",
    "    return tf.reduce_sum(tf.cast(correct_masked, tf.float32)) / tf.maximum(1.0, tf.reduce_sum(tf.cast(mask, tf.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Cropping3D, Concatenate, Dropout, BatchNormalization, Activation, ZeroPadding3D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "\n",
    "weights_classes = {\n",
    "    'background': 3,\n",
    "    'apo-ferritin': 1,\n",
    "    'beta-amylase': 1,\n",
    "    'beta-galactosidase': 1,\n",
    "    'ribosome': 1,\n",
    "    'thyroglobulin': 1,\n",
    "    'virus-like-particle': 1,\n",
    "}\n",
    "\n",
    "n_classes = 7\n",
    "\n",
    "def conv_block(inputs, n_filters, dropout=0, batch_norm=True):\n",
    "    x = Conv3D(n_filters, kernel_size=3, padding='same')(inputs)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv3D(n_filters, kernel_size=3, padding='same')(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if dropout > 0:\n",
    "        x = Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "# Créez le modèle avec une forme d'entrée définie\n",
    "def unet3d_model(input_shape, n_classes, filters=[16, 32, 64], dropout=0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # Encoder\n",
    "    c1 = conv_block(inputs, filters[0], dropout)\n",
    "    p1 = MaxPooling3D(pool_size=(2, 2, 2), padding=\"same\")(c1)\n",
    "\n",
    "    c2 = conv_block(p1, filters[1], dropout)\n",
    "    p2 = MaxPooling3D(pool_size=(2, 2, 2), padding=\"same\")(c2)\n",
    "\n",
    "    c3 = conv_block(p2, filters[2], dropout)\n",
    "    p3 = MaxPooling3D(pool_size=(2, 2, 2), padding=\"same\")(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    c4 = conv_block(p3, filters[2] * 2, dropout)\n",
    "    # Decoder\n",
    "    u3 = UpSampling3D(size=(2, 2, 2))(c4)\n",
    "    u3 = Concatenate()([u3, c3])\n",
    "    c5 = conv_block(u3, filters[2], dropout)\n",
    "\n",
    "    u2 = UpSampling3D(size=(2, 2, 2))(c5)\n",
    "    u2 = Concatenate()([u2, c2])\n",
    "    c6 = conv_block(u2, filters[1], dropout)\n",
    "\n",
    "    u1 = UpSampling3D(size=(2, 2, 2))(c6)\n",
    "    c1_pad = ZeroPadding3D(padding=((0, 1), (0, 1), (0, 1)))(c1)\n",
    "    u1 = Concatenate()([u1, c1_pad])\n",
    "    c7 = conv_block(u1, filters[0], dropout)\n",
    "\n",
    "    output_crop = Cropping3D(cropping=((0, 1), (0, 1), (0, 1)))(c7)\n",
    "    outputs = Conv3D(n_classes, kernel_size=1, activation='softmax')(output_crop)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (23, 79, 79, 1)\n",
    "n_classes = 7\n",
    "filters = [16, 32, 64]\n",
    "dropout = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_train_labels = np.argmax(Y_train, axis=-1).ravel()\n",
    "classes = np.unique(y_train_labels)\n",
    "\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=classes, \n",
    "    y=y_train_labels\n",
    ")\n",
    "\n",
    "class_weights = dict(zip(classes, class_weights_array))\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "i\n",
    "\n",
    "def weighted_categorical_crossentropy(class_weights):\n",
    "    \"\"\"\n",
    "    class_weights: tf.constant (ou un simple tableau/list) de taille [n_classes]\n",
    "    \"\"\"\n",
    "    # S'assurer que c'est un tenseur tf\n",
    "    class_weights = tf.constant(class_weights, dtype=tf.float32)\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_true et y_pred sont de forme [batch, ..., n_classes]\n",
    "        (dans votre cas : [batch, depth, height, width, n_classes] pour de la 3D)\n",
    "        \"\"\"\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0) # Pour éviter log(0)\n",
    "        \n",
    "        weighted_logprobs = y_true * tf.math.log(y_pred) * class_weights\n",
    "\n",
    "        return -tf.reduce_mean(tf.reduce_sum(weighted_logprobs, axis=-1))\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = weighted_categorical_crossentropy(class_weights_array)\n",
    "\n",
    "model = unet3d_model(input_shape=(23, 79, 79, 1), n_classes=n_classes, filters=filters, dropout=dropout)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy', protein_accuracy]\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',  # On surveille la perte sur le set de validation\n",
    "                                patience=5,         # Si la perte ne baisse pas pendant 5 époques, on arrête\n",
    "                                verbose=1,          # Affiche des informations sur l'arrêt anticipé\n",
    "                                restore_best_weights=True)  # Restaure les poids du meilleur modèle\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=1,\n",
    "    epochs=5,\n",
    "    validation_data=(X_val, Y_val)\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('unet3d_trained_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_segmentation_results(model, X_test, Y_test, class_labels, class_colors, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualise les résultats de la segmentation en comparant les images segmentées \"vraies\" et prédites.\n",
    "\n",
    "    Args:\n",
    "        model: Le modèle entraîné pour la segmentation.\n",
    "        X_test: Les données d'entrée de test.\n",
    "        Y_test: Les masques de vérité terrain (ground truth) pour les données de test.\n",
    "        class_labels: Dictionnaire mappant les indices de classe aux noms de classe.\n",
    "        class_colors: Dictionnaire mappant les indices de classe aux couleurs.\n",
    "        num_samples: Nombre d'exemples à visualiser.\n",
    "    \"\"\"\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, num_samples * 5))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image = X_test[idx].squeeze()\n",
    "        true_mask = np.argmax(Y_test[idx], axis=-1)\n",
    "        pred_mask = np.argmax(model.predict(X_test[idx][np.newaxis, ...]), axis=-1).squeeze()\n",
    "\n",
    "        slice_idx = np.random.randint(0, image.shape[0])\n",
    "\n",
    "        # Création d'une image colorée pour la vérité terrain\n",
    "        true_colored = np.zeros((true_mask.shape[1], true_mask.shape[2], 3), dtype=np.uint8)\n",
    "        for class_idx in np.unique(true_mask[slice_idx, :, :]):\n",
    "            true_colored[true_mask[slice_idx, :, :] == class_idx] = class_colors[class_idx]\n",
    "\n",
    "        # Création d'une image colorée pour la prédiction\n",
    "        pred_colored = np.zeros((pred_mask.shape[1], pred_mask.shape[2], 3), dtype=np.uint8)\n",
    "        for class_idx in np.unique(pred_mask[slice_idx, :, :]):\n",
    "            pred_colored[pred_mask[slice_idx, :, :] == class_idx] = class_colors[class_idx]\n",
    "\n",
    "        # Affichage de la vérité terrain\n",
    "        axes[i, 0].imshow(true_colored)\n",
    "        axes[i, 0].set_title(f\"Vérité Terrain (Slice Z={slice_idx})\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Ajout de la légende pour la vérité terrain\n",
    "        legend_patches_true = [\n",
    "            plt.Line2D([0], [0], color='white', marker='s', markersize=10, markerfacecolor=np.array(class_colors[class_idx]) / 255, label=class_labels[class_idx])\n",
    "            for class_idx in np.unique(true_mask[slice_idx, :, :])\n",
    "        ]\n",
    "        axes[i, 0].legend(handles=legend_patches_true, loc='upper right', fontsize=8)\n",
    "\n",
    "        # Affichage de la prédiction\n",
    "        axes[i, 1].imshow(pred_colored)\n",
    "        axes[i, 1].set_title(f\"Prédiction (Slice Z={slice_idx})\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "        # Ajout de la légende pour la prédiction\n",
    "        legend_patches_pred = [\n",
    "            plt.Line2D([0], [0], color='white', marker='s', markersize=10, markerfacecolor=np.array(class_colors[class_idx]) / 255, label=class_labels[class_idx])\n",
    "            for class_idx in np.unique(pred_mask[slice_idx, :, :])\n",
    "        ]\n",
    "        axes[i, 1].legend(handles=legend_patches_pred, loc='upper right', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assurez-vous que class_labels et class_colors sont définis\n",
    "class_labels = {\n",
    "    0: \"background\",\n",
    "    1: \"apo-ferritin\",\n",
    "    2: \"beta-amylase\",\n",
    "    3: \"beta-galactosidase\",\n",
    "    4: \"ribosome\",\n",
    "    5: \"thyroglobulin\",\n",
    "    6: \"virus-like-particle\"\n",
    "}\n",
    "\n",
    "class_colors = {\n",
    "    0: [0, 0, 0],        # Noir pour le fond\n",
    "    1: [255, 0, 0],      # Rouge pour apo-ferritin\n",
    "    2: [0, 0, 255],      # Bleu pour beta-amylase\n",
    "    3: [0, 255, 0],      # Vert pour beta-galactosidase\n",
    "    4: [255, 0, 255],    # Magenta pour ribosome\n",
    "    5: [255, 255, 0],    # Jaune pour thyroglobulin\n",
    "    6: [0, 255, 255]     # Cyan pour virus-like-particle\n",
    "}\n",
    "\n",
    "# Visualisation des résultats avec légende\n",
    "visualize_segmentation_results(model, X_test, Y_test, class_labels, class_colors, num_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, Y_test, batch_size=1)\n",
    "print(\"Loss      :\", results[0])\n",
    "print(\"Accuracy  :\", results[1])\n",
    "print(\"Prot. Acc :\", results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)  \n",
    "\n",
    "y_pred_argmax = np.argmax(y_pred, axis=-1) \n",
    "y_true_argmax = np.argmax(Y_test, axis=-1) \n",
    "\n",
    "y_pred_flat = y_pred_argmax.flatten()\n",
    "y_true_flat = y_true_argmax.flatten()\n",
    "\n",
    "class_names = [\n",
    "    cls_name for cls_name, cls_idx \n",
    "    in sorted(class_mapping.items(), key=lambda x: x[1])\n",
    "]\n",
    "\n",
    "print(class_names)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true_flat,\n",
    "    y_pred_flat,\n",
    "    target_names=class_names\n",
    ")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
