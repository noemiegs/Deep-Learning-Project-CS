{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "from config import DATA_DIR, TARGET_DIR\n",
    "import numpy as np\n",
    "\n",
    "def process_experiment_runs(base_dir):\n",
    "    # Dictionnaire pour stocker les résultats par TS\n",
    "    data_results = {}\n",
    "\n",
    "    # Parcourir tous les sous-dossiers dans ExperimentRuns\n",
    "    for ts_folder in os.listdir(base_dir):\n",
    "        ts_path = os.path.join(base_dir, ts_folder)\n",
    "\n",
    "        # Vérifier si le dossier contient un fichier Zarr\n",
    "        zarr_path = os.path.join(ts_path, \"VoxelSpacing10.000/denoised.zarr\")\n",
    "        if os.path.exists(zarr_path):\n",
    "            print(f\"Traitement de {ts_folder}...\")\n",
    "\n",
    "            # Charger le groupe Zarr\n",
    "            zgroup = zarr.open_group(zarr_path, mode='r')\n",
    "            \n",
    "            # Visualiser l'arborescence\n",
    "            print(f\"Arborescence pour {ts_folder}:\")\n",
    "            print(zgroup.tree())\n",
    "            \n",
    "            # Dictionnaire pour stocker les données de ce TS\n",
    "            ts_data = {}\n",
    "\n",
    "            # Parcourir les sous-groupes (0, 1, 2, ...)\n",
    "            for subgroup_key in zgroup.keys():\n",
    "                subgroup = zgroup[subgroup_key]\n",
    "\n",
    "                # Extraire les métadonnées et les données\n",
    "                ts_data[subgroup_key] = {\n",
    "                    \"attrs\": dict(subgroup.attrs),  # Convertir les métadonnées en dictionnaire\n",
    "                    \"info\": subgroup.info,\n",
    "                    \"data\": subgroup[:],  # Charger les données complètes\n",
    "                }\n",
    "\n",
    "            # Ajouter les données au dictionnaire global\n",
    "            data_results[ts_folder] = ts_data\n",
    "\n",
    "    return data_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Traiter les tomogrammes\n",
    "all_data = process_experiment_runs(DATA_DIR)\n",
    "\n",
    "# Sauvegarder les résultats ou continuer l'analyse\n",
    "print(\"Traitement terminé. Résumé des données extraites :\")\n",
    "for ts_name, ts_content in all_data.items():\n",
    "    print(f\"- {ts_name}: {len(ts_content)} sous-groupes traités.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TS_5_4'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TS_5_4']['0']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Afficher une coupe z=0 pour chaque résolution\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(all_data['TS_5_4']['0']['data'][0,:,:], cmap='gray')\n",
    "axs[0].set_title(\"Pleine résolution (184, 630, 630)\")\n",
    "axs[1].imshow(all_data['TS_5_4']['1']['data'][0,:,:], cmap='gray')\n",
    "axs[1].set_title(\"Moyenne résolution (92, 315, 315)\")\n",
    "axs[2].imshow(all_data['TS_5_4']['2']['data'][0,:,:], cmap='gray')\n",
    "axs[2].set_title(\"Basse résolution (46, 158, 158)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_targets(base_path):\n",
    "    # Dictionnaire pour stocker les informations de chaque tomogramme\n",
    "    target_data = {}\n",
    "\n",
    "    # Parcourir tous les dossiers dans le chemin de base (numéros de tomogrammes)\n",
    "    for tomogram_folder in os.listdir(base_path):\n",
    "        tomogram_path = os.path.join(base_path, tomogram_folder)\n",
    "\n",
    "        # Vérifier si un dossier \"Picks\" existe dans le tomogramme\n",
    "        picks_path = os.path.join(tomogram_path, \"Picks\")\n",
    "        if not os.path.exists(picks_path):\n",
    "            print(f\"Pas de dossier 'Picks' dans {tomogram_folder}\")\n",
    "            continue\n",
    "\n",
    "        # Parcourir tous les fichiers JSON dans le dossier \"Picks\"\n",
    "        for json_file in os.listdir(picks_path):\n",
    "            if json_file.endswith(\".json\"):\n",
    "                json_path = os.path.join(picks_path, json_file)\n",
    "\n",
    "                # Charger le fichier JSON\n",
    "                with open(json_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # Extraire le nom de la molécule et la localisation des points\n",
    "                molecule_name = data.get(\"pickable_object_name\", \"inconnu\")\n",
    "                points = data.get(\"points\", [])\n",
    "\n",
    "                # Ajouter les informations au dictionnaire\n",
    "                if tomogram_folder not in target_data:\n",
    "                    target_data[tomogram_folder] = {}\n",
    "\n",
    "                # Sauvegarder les données pour chaque molécule dans le tomogramme\n",
    "                target_data[tomogram_folder][molecule_name] = points\n",
    "\n",
    "    return target_data\n",
    "\n",
    "# Charger les targets\n",
    "all_targets = load_targets(TARGET_DIR)\n",
    "\n",
    "# Affichage des données chargées\n",
    "print(\"Résumé des données de targets :\")\n",
    "for tomogram, molecules in all_targets.items():\n",
    "    print(f\"- {tomogram}: {len(molecules)} molécules trouvées\")\n",
    "    for molecule, points in molecules.items():\n",
    "        print(f\"  * {molecule}: {len(points)} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import json\n",
    "\n",
    "def prepare_dataset(image_path, target_path):\n",
    "    \"\"\"\n",
    "    Prépare un dataset associant les données d'images aux targets (protéines et positions).\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Chemin vers le dossier contenant les images Zarr.\n",
    "        target_path (str): Chemin vers le dossier contenant les targets (fichiers JSON).\n",
    "\n",
    "    Returns:\n",
    "        list: Liste de dictionnaires, où chaque élément contient les données d'un tomogramme :\n",
    "            - \"name\": Nom du tomogramme.\n",
    "            - \"images\": Liste des résolutions (volumes 3D).\n",
    "            - \"targets\": Dictionnaire {type_molécule: [positions (x, y, z)]}.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "\n",
    "    # Parcourir les tomogrammes dans le dossier des images\n",
    "    for tomogram_name in os.listdir(image_path):\n",
    "        tomogram_image_path = os.path.join(image_path, tomogram_name, \"VoxelSpacing10.000/denoised.zarr\")\n",
    "        tomogram_target_path = os.path.join(target_path, tomogram_name, \"Picks\")\n",
    "\n",
    "        # Vérifier que les données Zarr et les targets existent\n",
    "        if not os.path.exists(tomogram_image_path):\n",
    "            print(f\"Images non trouvées pour {tomogram_name}, ignoré.\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(tomogram_target_path):\n",
    "            print(f\"Targets non trouvés pour {tomogram_name}, ignoré.\")\n",
    "            continue\n",
    "\n",
    "        # Charger les images (volumes 3D à plusieurs résolutions)\n",
    "        zgroup = zarr.open_group(tomogram_image_path, mode='r')\n",
    "        sorted_keys = sorted(zgroup.keys(), key=lambda k: np.prod(zgroup[k].shape), reverse=True)\n",
    "        images = [zgroup[key][:] for key in sorted_keys]\n",
    "\n",
    "        # Charger les targets (localisations des particules)\n",
    "        targets = {}\n",
    "        for json_file in os.listdir(tomogram_target_path):\n",
    "            if json_file.endswith(\".json\"):\n",
    "                json_path = os.path.join(tomogram_target_path, json_file)\n",
    "                with open(json_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    molecule_name = data.get(\"pickable_object_name\", \"unknown\")\n",
    "                    points = [\n",
    "                        [point[\"location\"][\"x\"], point[\"location\"][\"y\"], point[\"location\"][\"z\"]]\n",
    "                        for point in data[\"points\"]\n",
    "                    ]\n",
    "                    if molecule_name not in targets:\n",
    "                        targets[molecule_name] = []\n",
    "                    targets[molecule_name].extend(points)\n",
    "\n",
    "        # Ajouter les données du tomogramme au dataset\n",
    "        dataset.append({\n",
    "            \"name\": tomogram_name,\n",
    "            \"images\": images,  # Liste des résolutions\n",
    "            \"targets\": targets  # Localisations des particules par type\n",
    "        })\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# print tomogram shapes for each resolution in the order of the dataset\n",
    "def print_shapes(dataset):\n",
    "    for tomogram in dataset:\n",
    "        print(f\"Tomogramme {tomogram['name']}:\")\n",
    "        for i, image in enumerate(tomogram['images']):\n",
    "            print(f\"  - Résolution {i}: {image.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins des données\n",
    "\n",
    "# Préparer le dataset\n",
    "dataset = prepare_dataset(DATA_DIR, TARGET_DIR)\n",
    "\n",
    "print_shapes(dataset)\n",
    "\n",
    "# Exemple : Afficher les données du premier tomogramme\n",
    "print(f\"Nom du tomogramme : {dataset[0]['name']}\")\n",
    "print(f\"Forme de l'image (résolution 1) : {dataset[0]['images'][0].shape}\")\n",
    "print(f\"Targets : {dataset[0]['targets']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# On suppose que les dictionnaires all_data et all_targets ont été générés par vos fonctions process_experiment_runs et load_targets.\n",
    "# Par exemple :\n",
    "#   all_data = process_experiment_runs(DATA_DIR)\n",
    "#   all_targets = load_targets(TARGET_DIR)\n",
    "\n",
    "voxel_size = 10  # Même valeur utilisée lors du chargement et de l'analyse\n",
    "\n",
    "# Choisir un tomogramme et une résolution (ici, 'TS_5_4' et le groupe '0' pour la pleine résolution)\n",
    "tomogram_folder = 'TS_5_4'\n",
    "resolution_group = '0'\n",
    "slice_index = 90  # Coupe à afficher sur l'axe Z\n",
    "\n",
    "# Charger la coupe du tomogramme\n",
    "tomogram_volume = all_data[tomogram_folder][resolution_group]['data']\n",
    "image_slice = tomogram_volume[slice_index, :, :]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image_slice, cmap='gray')\n",
    "plt.title(f\"Tomogramme {tomogram_folder} - Coupe Z={slice_index}\")\n",
    "\n",
    "# Vérifier si des cibles (targets) sont présentes pour ce tomogramme\n",
    "if tomogram_folder in all_targets:\n",
    "    molecules = all_targets[tomogram_folder]\n",
    "    \n",
    "    # Pour éviter les doublons dans la légende\n",
    "    legend_entries = {}\n",
    "    \n",
    "    for molecule, points in molecules.items():\n",
    "        for point in points:\n",
    "            # Extraction des coordonnées depuis la clé \"location\"\n",
    "            x = point[\"location\"][\"x\"] / voxel_size\n",
    "            y = point[\"location\"][\"y\"] / voxel_size\n",
    "            z = point[\"location\"][\"z\"] / voxel_size  # Coordonnée Z en voxels\n",
    "            \n",
    "            # N'afficher que les points proches de la coupe sélectionnée\n",
    "            if abs(z - slice_index) < 3:  # Seuil ajustable selon la précision désirée\n",
    "                sc = plt.scatter(x, y, s=20)\n",
    "                if molecule not in legend_entries:\n",
    "                    legend_entries[molecule] = sc\n",
    "\n",
    "    if legend_entries:\n",
    "        plt.legend(legend_entries.values(), legend_entries.keys(), loc='upper right')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Concatenate, Dropout, BatchNormalization, Activation\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# def conv_block(inputs, n_filters, dropout=0, batch_norm=True):\n",
    "#     \"\"\"\n",
    "#     Bloc de convolutions 3D utilisé dans l'encodeur et le décodeur.\n",
    "#     Deux convolutions successives avec option de BatchNormalization et Dropout.\n",
    "#     \"\"\"\n",
    "#     # Première convolution\n",
    "#     x = Conv3D(n_filters, kernel_size=3, padding='same')(inputs)\n",
    "#     if batch_norm:\n",
    "#         x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "#     # Deuxième convolution\n",
    "#     x = Conv3D(n_filters, kernel_size=3, padding='same')(x)\n",
    "#     if batch_norm:\n",
    "#         x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "#     if dropout > 0:\n",
    "#         x = Dropout(dropout)(x)\n",
    "#     return x\n",
    "\n",
    "# def unet3d_model(input_shape, n_classes, filters=[48, 64, 128], dropout=0):\n",
    "#     \"\"\"\n",
    "#     Construction du modèle U-Net 3D.\n",
    "    \n",
    "#     Paramètres :\n",
    "#       - input_shape : tuple indiquant la forme d'entrée (ex: (160,160,160,1))\n",
    "#       - n_classes   : nombre de classes à prédire (par ex. 8)\n",
    "#       - filters     : liste contenant le nombre de filtres à utiliser pour chaque niveau de l'encodeur\n",
    "#       - dropout     : taux de dropout (peut être mis à 0 pour aucune régularisation)\n",
    "      \n",
    "#     Retourne un modèle Keras compilé.\n",
    "#     \"\"\"\n",
    "#     inputs = Input(input_shape)\n",
    "    \n",
    "#     # Chemin descendant (encodeur)\n",
    "#     c1 = conv_block(inputs, filters[0], dropout)\n",
    "#     p1 = MaxPooling3D(pool_size=(2,2,2))(c1)\n",
    "    \n",
    "#     c2 = conv_block(p1, filters[1], dropout)\n",
    "#     p2 = MaxPooling3D(pool_size=(2,2,2))(c2)\n",
    "    \n",
    "#     c3 = conv_block(p2, filters[2], dropout)\n",
    "#     p3 = MaxPooling3D(pool_size=(2,2,2))(c3)\n",
    "    \n",
    "#     # Goulot d'étranglement (bottleneck)\n",
    "#     c4 = conv_block(p3, filters[2]*2, dropout)\n",
    "    \n",
    "#     # Chemin ascendant (décodeur)\n",
    "#     u3 = UpSampling3D(size=(2,2,2))(c4)\n",
    "#     u3 = Concatenate()([u3, c3])\n",
    "#     c5 = conv_block(u3, filters[2], dropout)\n",
    "    \n",
    "#     u2 = UpSampling3D(size=(2,2,2))(c5)\n",
    "#     u2 = Concatenate()([u2, c2])\n",
    "#     c6 = conv_block(u2, filters[1], dropout)\n",
    "    \n",
    "#     u1 = UpSampling3D(size=(2,2,2))(c6)\n",
    "#     u1 = Concatenate()([u1, c1])\n",
    "#     c7 = conv_block(u1, filters[0], dropout)\n",
    "    \n",
    "#     # Couche finale : convolution 1x1x1 pour obtenir n_classes canaux en sortie avec activation softmax.\n",
    "#     outputs = Conv3D(n_classes, kernel_size=1, activation='softmax')(c7)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "#     return model\n",
    "\n",
    "# # Exemple d'utilisation du modèle U-Net 3D\n",
    "# patch_size = 160  # taille du patch d'entrée\n",
    "# input_shape = (patch_size, patch_size, patch_size, 1)  # volume en niveaux de gris\n",
    "# n_classes = 8\n",
    "# filters = [48, 64, 128]\n",
    "# dropout = 0\n",
    "\n",
    "# model = unet3d_model(input_shape, n_classes, filters, dropout)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Concatenate, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import numpy as np\n",
    "\n",
    "#############################################\n",
    "# Définition d'un U-Net 3D allégé\n",
    "#############################################\n",
    "\n",
    "def conv_block(inputs, n_filters, dropout=0, batch_norm=True):\n",
    "    \"\"\"\n",
    "    Bloc de convolutions 3D réduit : deux convolutions avec BatchNormalization et ReLU.\n",
    "    \"\"\"\n",
    "    x = Conv3D(n_filters, kernel_size=3, padding='same')(inputs)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv3D(n_filters, kernel_size=3, padding='same')(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    if dropout > 0:\n",
    "        x = Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def unet3d_small(input_shape, n_classes, filters=[16, 32, 64], dropout=0):\n",
    "    \"\"\"\n",
    "    Construction d'un U-Net 3D plus léger.\n",
    "    \n",
    "    Paramètres :\n",
    "      - input_shape : par exemple (64, 64, 64, 1)\n",
    "      - n_classes   : nombre de classes (ex: 8)\n",
    "      - filters     : liste avec un nombre réduit de filtres pour chaque niveau\n",
    "      - dropout     : taux de dropout (optionnel)\n",
    "      \n",
    "    Renvoie le modèle Keras.\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encodeur\n",
    "    c1 = conv_block(inputs, filters[0], dropout)\n",
    "    p1 = MaxPooling3D(pool_size=(2,2,2))(c1)\n",
    "    \n",
    "    c2 = conv_block(p1, filters[1], dropout)\n",
    "    p2 = MaxPooling3D(pool_size=(2,2,2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = conv_block(p2, filters[2], dropout)\n",
    "    \n",
    "    # Décodeur\n",
    "    u2 = UpSampling3D(size=(2,2,2))(c3)\n",
    "    u2 = Concatenate()([u2, c2])\n",
    "    c4 = conv_block(u2, filters[1], dropout)\n",
    "    \n",
    "    u1 = UpSampling3D(size=(2,2,2))(c4)\n",
    "    u1 = Concatenate()([u1, c1])\n",
    "    c5 = conv_block(u1, filters[0], dropout)\n",
    "    \n",
    "    # Couche finale : convolution 1x1x1 pour produire n_classes canaux avec softmax\n",
    "    outputs = Conv3D(n_classes, kernel_size=1, activation='softmax')(c5)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "#############################################\n",
    "# Paramètres et compilation du modèle allégé\n",
    "#############################################\n",
    "\n",
    "patch_size = 64  # Taille réduite pour diminuer l'utilisation mémoire\n",
    "input_shape = (patch_size, patch_size, patch_size, 1)  # Volume d'entrée (1 canal)\n",
    "n_classes = 8\n",
    "filters = [16, 32, 64]\n",
    "dropout = 0\n",
    "\n",
    "model = unet3d_small(input_shape, n_classes, filters, dropout)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss=CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Résumé du modèle U-Net 3D allégé :\")\n",
    "model.summary()\n",
    "\n",
    "#############################################\n",
    "# Simulation d'un entraînement avec des données factices\n",
    "#############################################\n",
    "\n",
    "# Nombre d'échantillons factices\n",
    "num_samples = 10\n",
    "\n",
    "# Générer des volumes d'entrée aléatoires\n",
    "X_train = np.random.rand(num_samples, patch_size, patch_size, patch_size, 1).astype(np.float32)\n",
    "\n",
    "# Générer des masques de segmentation factices (classes entières)\n",
    "y_train_int = np.random.randint(0, n_classes, size=(num_samples, patch_size, patch_size, patch_size))\n",
    "# Conversion en encodage one-hot\n",
    "y_train = tf.keras.utils.to_categorical(y_train_int, num_classes=n_classes)\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train, y_train, batch_size=1, epochs=5)\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "model.save('unet3d_small_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def gaussian_filter_3d(volume, sigma):\n",
    "    \"\"\"\n",
    "    Applique un flou gaussien à un volume 3D en traitant chaque slice 2D individuellement.\n",
    "    \n",
    "    Args:\n",
    "        volume (np.array): Volume 3D (z, y, x).\n",
    "        sigma (float): Écart-type pour le noyau gaussien.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Volume 3D flouté.\n",
    "    \"\"\"\n",
    "    blurred_volume = np.zeros_like(volume, dtype=np.float32)\n",
    "    for z in range(volume.shape[0]):  # Itérer sur les slices 2D\n",
    "        blurred_volume[z] = cv2.GaussianBlur(volume[z], (0, 0), sigma)\n",
    "    return blurred_volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "def create_heatmaps(volume_shape, targets, sigma=3, method=\"opencv\"):\n",
    "    \"\"\"\n",
    "    Crée des heatmaps multi-canaux pour les targets avec un flou gaussien.\n",
    "    \n",
    "    Args:\n",
    "        volume_shape (tuple): Dimensions du volume 3D.\n",
    "        targets (dict): Targets {type_molecule: [positions (x, y, z)]}.\n",
    "        sigma (float): Écart-type pour le flou gaussien.\n",
    "        method (str): Méthode pour appliquer le flou (\"opencv\" ou \"numpy\").\n",
    "\n",
    "    Returns:\n",
    "        np.array: Heatmaps multi-canaux de dimensions (num_molecules, *volume_shape).\n",
    "    \"\"\"\n",
    "    molecule_names = list(targets.keys())\n",
    "    heatmaps = np.zeros((len(molecule_names), *volume_shape), dtype=np.float32)\n",
    "\n",
    "    for i, molecule_name in enumerate(molecule_names):\n",
    "        for x, y, z in targets[molecule_name]:\n",
    "            if 0 <= x < volume_shape[2] and 0 <= y < volume_shape[1] and 0 <= z < volume_shape[0]:\n",
    "                heatmaps[i, int(z), int(y), int(x)] += 1\n",
    "\n",
    "        # Appliquer le flou gaussien\n",
    "        if method == \"opencv\":\n",
    "            heatmaps[i] = gaussian_filter_3d(heatmaps[i], sigma=sigma)\n",
    "        \n",
    "            if i==0:\n",
    "            # plot the heatmap in napari\n",
    "                viewer = napari.view_image(heatmaps[i])\n",
    "                viewer.add_image(heatmaps[i], name='heatmap')\n",
    "\n",
    "                # run the viewer\n",
    "                napari.run()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Méthode de flou inconnue : choisissez 'opencv' ou 'numpy'.\")\n",
    "\n",
    "    return heatmaps, molecule_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, Model\n",
    "\n",
    "# def unet_3d(input_shape, num_classes):\n",
    "#     \"\"\"\n",
    "#     Implémentation d'un U-Net 3D en TensorFlow/Keras.\n",
    "\n",
    "#     Args:\n",
    "#         input_shape (tuple): Dimensions de l'entrée (z, y, x, c).\n",
    "#         num_classes (int): Nombre de canaux de sortie (types de particules).\n",
    "\n",
    "#     Returns:\n",
    "#         tf.keras.Model: Modèle U-Net 3D.\n",
    "#     \"\"\"\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "#     # Encodeur\n",
    "#     x1 = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "#     x1 = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')(x1)\n",
    "#     p1 = layers.MaxPooling3D(pool_size=2)(x1)\n",
    "\n",
    "#     x2 = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')(p1)\n",
    "#     x2 = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')(x2)\n",
    "#     p2 = layers.MaxPooling3D(pool_size=2)(x2)\n",
    "\n",
    "#     x3 = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same')(p2)\n",
    "#     x3 = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same')(x3)\n",
    "#     p3 = layers.MaxPooling3D(pool_size=2)(x3)\n",
    "\n",
    "#     # Bottleneck\n",
    "#     bn = layers.Conv3D(256, kernel_size=3, activation='relu', padding='same')(p3)\n",
    "#     bn = layers.Conv3D(256, kernel_size=3, activation='relu', padding='same')(bn)\n",
    "\n",
    "#     # Décodeur\n",
    "#     u3 = layers.Conv3DTranspose(128, kernel_size=2, strides=2, padding='same')(bn)\n",
    "#     u3 = layers.concatenate([u3, x3])\n",
    "#     u3 = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same')(u3)\n",
    "#     u3 = layers.Conv3D(128, kernel_size=3, activation='relu', padding='same')(u3)\n",
    "\n",
    "#     u2 = layers.Conv3DTranspose(64, kernel_size=2, strides=2, padding='same')(u3)\n",
    "#     u2 = layers.concatenate([u2, x2])\n",
    "#     u2 = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')(u2)\n",
    "#     u2 = layers.Conv3D(64, kernel_size=3, activation='relu', padding='same')(u2)\n",
    "\n",
    "#     u1 = layers.Conv3DTranspose(32, kernel_size=2, strides=2, padding='same')(u2)\n",
    "#     u1 = layers.concatenate([u1, x1])\n",
    "#     u1 = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')(u1)\n",
    "#     u1 = layers.Conv3D(32, kernel_size=3, activation='relu', padding='same')(u1)\n",
    "\n",
    "#     # Sortie\n",
    "#     outputs = layers.Conv3D(num_classes, kernel_size=1, activation='sigmoid')(u1)\n",
    "\n",
    "#     return Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        Modèle U-Net 3D pour prédire les heatmaps multi-canaux.\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int): Nombre de canaux d'entrée (1 pour volumes 3D en niveaux de gris).\n",
    "            out_channels (int): Nombre de canaux de sortie (correspondant aux types de particules).\n",
    "        \"\"\"\n",
    "        super(UNet3D, self).__init__()\n",
    "        \n",
    "        # Encoder (réduction de dimension)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder (remonter les dimensions)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv3d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, out_channels, kernel_size=1)  # Une heatmap par type de particule\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# model summary from torchsummary\n",
    "from torchsummary import summary\n",
    "model_test = UNet3D(in_channels=1, out_channels=6).to('cuda')\n",
    "# input shape from the first tomogram (small resolution)\n",
    "input_shape = (1, 46, 158, 158) # (channels, z, y, x)\n",
    "# size of the first tomogram of the test dataset\n",
    "sizeof_first_tomogram = dataset[0]['images'][2].shape\n",
    "print(f\"Size of the first tomogram: {sizeof_first_tomogram}\")\n",
    "summary(model_test, input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TomogramDataset(Dataset):\n",
    "    def __init__(self, dataset, target_size=(64, 128, 128), sigma=3, res_channel=2):\n",
    "        \"\"\"\n",
    "        Dataset PyTorch pour les tomogrammes avec heatmaps générées à partir des targets.\n",
    "\n",
    "        Args:\n",
    "            dataset (list): Liste contenant les images et targets.\n",
    "            target_size (tuple): Taille cible des volumes et heatmaps (D, H, W).\n",
    "            sigma (float): Écart-type pour le flou gaussien des heatmaps.\n",
    "            res_channel (int): Indice de la résolution à utiliser pour les images. Exemple : 2 pour la basse résolution ()\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.target_size = target_size  # Taille cible\n",
    "        for tomogram in dataset:\n",
    "            volume_shape = tomogram[\"images\"][res_channel].shape\n",
    "            heatmaps, _ = create_heatmaps(volume_shape, tomogram[\"targets\"], sigma=sigma)\n",
    "            self.data.append({\"image\": tomogram[\"images\"][res_channel], \"heatmaps\": heatmaps})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        \n",
    "        # Charger et convertir en tenseurs\n",
    "        image = torch.tensor(sample[\"image\"], dtype=torch.float32).unsqueeze(0)  # Supprimer une dimension channel\n",
    "        heatmaps = torch.tensor(sample[\"heatmaps\"], dtype=torch.float32)\n",
    "        \n",
    "        # # Redimensionner à la taille cible\n",
    "        # image = F.interpolate(image.unsqueeze(0), size=self.target_size, mode='trilinear', align_corners=False).squeeze(0)\n",
    "        # heatmaps = F.interpolate(heatmaps.unsqueeze(0), size=self.target_size, mode='trilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        return image, heatmaps\n",
    "\n",
    "# Préparer le DataLoader\n",
    "train_loader = DataLoader(TomogramDataset(dataset, target_size=(64, 128, 128)), batch_size=2, shuffle=True)\n",
    "\n",
    "# taille des données du train_loader\n",
    "for image, heatmaps in train_loader:\n",
    "    print(f\"Taille de l'image : {image.shape}\")\n",
    "    print(f\"Taille des heatmaps : {heatmaps.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Vérifie si un GPU est disponible\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU disponible :\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU non disponible. Utilisation du CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# Initialiser le modèle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPUdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')print('Using device:', device)print()\n",
    "#Additional Info when using cudaif device.type == 'cuda':\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print('Memory Usage:')\n",
    "print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet3D(in_channels=1, out_channels=len(dataset[0][\"targets\"])).to(device)\n",
    "print(\"out_channel\",len(dataset[0][\"targets\"]))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, heatmaps in train_loader:\n",
    "        images, heatmaps = images.to(device), heatmaps.to(device)\n",
    "\n",
    "        # Réinitialiser les gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calcul de la perte\n",
    "        loss = criterion(outputs, heatmaps)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimisation\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les poids du modèle\n",
    "model_save_path = \"unet3d_weights.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Modèle sauvegardé dans {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des tomogrammes d'intérêt\n",
    "selected_tomograms = [\"TS_5_4\", \"TS_6_4\", \"TS_69_2\"]\n",
    "\n",
    "# Filtrer le dataset\n",
    "test_dataset = [tomogram for tomogram in dataset if tomogram[\"name\"] in selected_tomograms]\n",
    "\n",
    "# Vérifier les tomogrammes sélectionnés\n",
    "print(f\"Tomogrammes sélectionnés ({len(test_dataset)}): {[t['name'] for t in test_dataset]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un DataLoader pour les tomogrammes sélectionnés\n",
    "test_loader = DataLoader(\n",
    "    TomogramDataset(test_dataset, target_size=(64, 128, 128)),\n",
    "    batch_size=1,  # Une image à la fois pour une meilleure visualisation\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle\n",
    "model = UNet3D(in_channels=1, out_channels=6).to(device)\n",
    "model.load_state_dict(torch.load(\"unet3d_weights.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Tester sur les tomogrammes sélectionnés\n",
    "for idx, (images, heatmaps) in enumerate(test_loader):\n",
    "    images = images.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Obtenir les prédictions\n",
    "        predictions = model(images)\n",
    "    \n",
    "    # Convertir les prédictions en numpy pour visualisation ou post-traitement\n",
    "    predictions_np = predictions.cpu().numpy()\n",
    "    print(f\"Prédictions pour le tomogramme {test_dataset[idx]['name']}:\")\n",
    "    print(predictions_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# napari pour visualiser le tomogramme avant et après le traitement  en côte à côte\t\n",
    "import napari\n",
    "\n",
    "# Créer une nouvelle instance de napari\n",
    "viewer = napari.Viewer()\n",
    "print(test_dataset[0][\"images\"][0].shape)\n",
    "# viewer.add_image(test_dataset[0][\"images\"][0], name=\"Original\", colormap=\"gray\", blending=\"additive\")\n",
    "print(predictions_np[0, 0].shape)\n",
    "viewer.add_image(predictions_np[0, 0], name=\"Prédiction\", colormap=\"viridis\", blending=\"additive\")\n",
    "\n",
    "# # Afficher les points de la première molécule\n",
    "# points = test_dataset[0][\"targets\"][\"ribosome\"]\n",
    "# viewer.add_points(points, size=5, face_color='red', name=\"Ribosome\")\n",
    "\n",
    "# # Afficher les points de la deuxième molécule\n",
    "# points = test_dataset[0][\"targets\"][\"unknown\"]\n",
    "# viewer.add_points(points, size=5, face_color='blue', name=\"Inconnu\")\n",
    "\n",
    "# # Afficher les points de la troisième molécule\n",
    "# points = test_dataset[0][\"targets\"][\"unknown_2\"]\n",
    "# viewer.add_points(points, size=5, face_color='green', name=\"Inconnu_2\")\n",
    "\n",
    "# # Afficher les points de la quatrième molécule\n",
    "# points = test_dataset[0][\"targets\"][\"unknown_3\"]\n",
    "# viewer.add_points(points, size=5, face_color='yellow', name=\"Inconnu_3\")\n",
    "\n",
    "# # Afficher les points de la cinquième molécule\n",
    "# points = test_dataset[0][\"targets\"][\"unknown_4\"]\n",
    "# viewer.add_points(points, size=5, face_color='orange', name=\"Inconnu_4\")\n",
    "\n",
    "# # Afficher les points de la sixième molécule\n",
    "# points = test_dataset[0][\"targets\"][\"unknown_5\"]\n",
    "# viewer.add_points(points, size=5, face_color='purple', name=\"Inconnu_5\")\n",
    "\n",
    "# Lancer l'interface graphique\n",
    "napari.run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données pour napari (une seule classe ou un volume entier)\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(predictions_np[0, 1], colormap=\"magma\", name=\"Classe 1\")\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[0]['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_metrics(predictions, targets, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcule les métriques IoU, Dice et MSE entre les prédictions et les targets.\n",
    "\n",
    "    Args:\n",
    "        predictions (torch.Tensor): Tenseur des prédictions.\n",
    "        targets (torch.Tensor): Tenseur des targets.\n",
    "        threshold (float): Seuil pour binariser les prédictions.\n",
    "\n",
    "    Returns:\n",
    "        dict: Métriques calculées.\n",
    "    \"\"\"\n",
    "    # Binariser les prédictions\n",
    "    binary_preds = (predictions > threshold).float()\n",
    "    binary_targets = (targets > threshold).float()\n",
    "    \n",
    "    # Intersection et union pour IoU\n",
    "    intersection = (binary_preds * binary_targets).sum()\n",
    "    union = (binary_preds + binary_targets).clamp(0, 1).sum()\n",
    "    iou = intersection / (union + 1e-8)  # Ajouter un epsilon pour éviter la division par zéro\n",
    "\n",
    "    # Dice coefficient\n",
    "    dice = (2 * intersection) / (binary_preds.sum() + binary_targets.sum() + 1e-8)\n",
    "\n",
    "    # MSE\n",
    "    mse = ((predictions - targets) ** 2).mean()\n",
    "\n",
    "    return {\"IoU\": iou.item(), \"Dice\": dice.item(), \"MSE\": mse.item()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résultats des métriques pour chaque tomogramme\n",
    "results = []\n",
    "\n",
    "model.eval()\n",
    "for idx, (images, targets) in enumerate(test_loader):\n",
    "    images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Prédictions\n",
    "        predictions = model(images)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calcul des métriques\n",
    "    metrics = compute_metrics(predictions[0], targets[0])  # Comparer une instance\n",
    "    metrics[\"name\"] = test_dataset[idx][\"name\"]\n",
    "    results.append(metrics)\n",
    "\n",
    "# Afficher les résultats pour chaque tomogramme\n",
    "for result in results:\n",
    "    print(f\"Tomogramme: {result['name']}, IoU: {result['IoU']:.4f}, Dice: {result['Dice']:.4f}, MSE: {result['MSE']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sélectionner un échantillon pour la visualisation\n",
    "sample_idx = 0  # Premier échantillon dans le test_loader\n",
    "sample_name = test_dataset[sample_idx][\"name\"]\n",
    "\n",
    "# Charger l'image, les prédictions et les labels\n",
    "images, targets = next(iter(test_loader))\n",
    "images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(images)\n",
    "\n",
    "# Convertir en numpy\n",
    "image_np = images[0, 0].cpu().numpy()  # Image 3D\n",
    "predictions_np = predictions[0].cpu().numpy()  # Prédictions 3D multi-canaux\n",
    "targets_np = targets[0].cpu().numpy()  # Labels 3D multi-canaux\n",
    "\n",
    "# Sélectionner la coupe médiane en Z\n",
    "z_slice = image_np.shape[0] // 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Image originale\n",
    "axes[0].imshow(image_np[z_slice], cmap=\"gray\")\n",
    "axes[0].set_title(f\"Image originale - {sample_name}\")\n",
    "\n",
    "# Labels réels en superposition (coloré par type de molécule)\n",
    "target_overlay = np.zeros((*targets_np.shape[1:], 3))  # Image couleur\n",
    "for i in range(targets_np.shape[0]):  # Parcourir les canaux (molécules)\n",
    "    target_overlay[..., i % 3] += targets_np[i, z_slice]  # Ajouter au canal R, G ou B\n",
    "\n",
    "axes[1].imshow(image_np[z_slice], cmap=\"gray\")\n",
    "axes[1].imshow(target_overlay, alpha=0.5)  # Superposition semi-transparente\n",
    "axes[1].set_title(\"Labels réels\")\n",
    "\n",
    "# Prédictions en superposition (coloré par type de molécule)\n",
    "prediction_overlay = np.zeros((*predictions_np.shape[1:], 3))  # Image couleur\n",
    "for i in range(predictions_np.shape[0]):\n",
    "    prediction_overlay[..., i % 3] += predictions_np[i, z_slice]\n",
    "\n",
    "axes[2].imshow(image_np[z_slice], cmap=\"gray\")\n",
    "axes[2].imshow(prediction_overlay, alpha=0.5)\n",
    "axes[2].set_title(\"Prédictions\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
