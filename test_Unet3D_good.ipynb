{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "from config import DATA_DIR, TARGET_DIR\n",
    "import numpy as np\n",
    "\n",
    "def process_experiment_runs(base_dir):\n",
    "    # Dictionnaire pour stocker les r√©sultats par TS\n",
    "    data_results = {}\n",
    "\n",
    "    # Parcourir tous les sous-dossiers dans ExperimentRuns\n",
    "    for ts_folder in os.listdir(base_dir):\n",
    "        ts_path = os.path.join(base_dir, ts_folder)\n",
    "\n",
    "        # V√©rifier si le dossier contient un fichier Zarr\n",
    "        zarr_path = os.path.join(ts_path, \"VoxelSpacing10.000/denoised.zarr\")\n",
    "        if os.path.exists(zarr_path):\n",
    "            print(f\"Traitement de {ts_folder}...\")\n",
    "\n",
    "            # Charger le groupe Zarr\n",
    "            zgroup = zarr.open_group(zarr_path, mode='r')\n",
    "            \n",
    "            # Visualiser l'arborescence\n",
    "            print(f\"Arborescence pour {ts_folder}:\")\n",
    "            print(zgroup.tree())\n",
    "            \n",
    "            # Dictionnaire pour stocker les donn√©es de ce TS\n",
    "            ts_data = {}\n",
    "\n",
    "            # Parcourir les sous-groupes (0, 1, 2, ...)\n",
    "            for subgroup_key in zgroup.keys():\n",
    "                subgroup = zgroup[subgroup_key]\n",
    "\n",
    "                # Extraire les m√©tadonn√©es et les donn√©es\n",
    "                ts_data[subgroup_key] = {\n",
    "                    \"attrs\": dict(subgroup.attrs),  # Convertir les m√©tadonn√©es en dictionnaire\n",
    "                    \"info\": subgroup.info,\n",
    "                    \"data\": subgroup[:],  # Charger les donn√©es compl√®tes\n",
    "                }\n",
    "\n",
    "            # Ajouter les donn√©es au dictionnaire global\n",
    "            data_results[ts_folder] = ts_data\n",
    "\n",
    "    return data_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Traiter les tomogrammes\n",
    "all_data = process_experiment_runs(DATA_DIR)\n",
    "\n",
    "# Sauvegarder les r√©sultats ou continuer l'analyse\n",
    "print(\"Traitement termin√©. R√©sum√© des donn√©es extraites :\")\n",
    "for ts_name, ts_content in all_data.items():\n",
    "    print(f\"- {ts_name}: {len(ts_content)} sous-groupes trait√©s.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TS_5_4'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TS_5_4']['0']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Afficher une coupe z=0 pour chaque r√©solution\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(all_data['TS_5_4']['0']['data'][0,:,:], cmap='gray')\n",
    "axs[0].set_title(\"Pleine r√©solution (184, 630, 630)\")\n",
    "axs[1].imshow(all_data['TS_5_4']['1']['data'][0,:,:], cmap='gray')\n",
    "axs[1].set_title(\"Moyenne r√©solution (92, 315, 315)\")\n",
    "axs[2].imshow(all_data['TS_5_4']['2']['data'][0,:,:], cmap='gray')\n",
    "axs[2].set_title(\"Basse r√©solution (46, 158, 158)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_targets(base_path):\n",
    "    # Dictionnaire pour stocker les informations de chaque tomogramme\n",
    "    target_data = {}\n",
    "\n",
    "    # Parcourir tous les dossiers dans le chemin de base (num√©ros de tomogrammes)\n",
    "    for tomogram_folder in os.listdir(base_path):\n",
    "        tomogram_path = os.path.join(base_path, tomogram_folder)\n",
    "\n",
    "        # V√©rifier si un dossier \"Picks\" existe dans le tomogramme\n",
    "        picks_path = os.path.join(tomogram_path, \"Picks\")\n",
    "        if not os.path.exists(picks_path):\n",
    "            print(f\"Pas de dossier 'Picks' dans {tomogram_folder}\")\n",
    "            continue\n",
    "\n",
    "        # Parcourir tous les fichiers JSON dans le dossier \"Picks\"\n",
    "        for json_file in os.listdir(picks_path):\n",
    "            if json_file.endswith(\".json\"):\n",
    "                json_path = os.path.join(picks_path, json_file)\n",
    "\n",
    "                # Charger le fichier JSON\n",
    "                with open(json_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # Extraire le nom de la mol√©cule et la localisation des points\n",
    "                molecule_name = data.get(\"pickable_object_name\", \"inconnu\")\n",
    "                points = data.get(\"points\", [])\n",
    "\n",
    "                # Ajouter les informations au dictionnaire\n",
    "                if tomogram_folder not in target_data:\n",
    "                    target_data[tomogram_folder] = {}\n",
    "\n",
    "                # Sauvegarder les donn√©es pour chaque mol√©cule dans le tomogramme\n",
    "                target_data[tomogram_folder][molecule_name] = points\n",
    "\n",
    "    return target_data\n",
    "\n",
    "# Charger les targets\n",
    "all_targets = load_targets(TARGET_DIR)\n",
    "\n",
    "# Affichage des donn√©es charg√©es\n",
    "print(\"R√©sum√© des donn√©es de targets :\")\n",
    "for tomogram, molecules in all_targets.items():\n",
    "    print(f\"- {tomogram}: {len(molecules)} mol√©cules trouv√©es\")\n",
    "    for molecule, points in molecules.items():\n",
    "        print(f\"  * {molecule}: {len(points)} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# --- Histogramme global ---\n",
    "global_counts = {}\n",
    "for tomogram, molecules in all_targets.items():\n",
    "    for molecule, points in molecules.items():\n",
    "        global_counts[molecule] = global_counts.get(molecule, 0) + len(points)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(global_counts.keys(), global_counts.values(), color='skyblue')\n",
    "plt.xlabel(\"Type de prot√©ine\")\n",
    "plt.ylabel(\"Nombre d'exemplaires\")\n",
    "plt.title(\"Histogramme global du nombre d'exemplaires de prot√©ines\")\n",
    "plt.show()\n",
    "\n",
    "# --- Histogrammes d√©taill√©s par tomogramme ---\n",
    "# D√©terminer le nombre de tomogrammes √† afficher\n",
    "num_tomograms = len(all_targets)\n",
    "# Choisir une disposition en grille adapt√©e (par exemple 2 colonnes si plus de 2 tomogrammes)\n",
    "cols = 2\n",
    "rows = math.ceil(num_tomograms / cols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*6, rows*4), squeeze=False)\n",
    "\n",
    "# Parcourir les tomogrammes et tracer l'histogramme pour chacun\n",
    "tomogram_names = list(all_targets.keys())\n",
    "for idx, tomogram in enumerate(tomogram_names):\n",
    "    row = idx // cols\n",
    "    col = idx % cols\n",
    "    ax = axes[row][col]\n",
    "    \n",
    "    # Calculer le nombre d'exemplaires pour chaque prot√©ine dans ce tomogramme\n",
    "    counts = {molecule: len(points) for molecule, points in all_targets[tomogram].items()}\n",
    "    \n",
    "    ax.bar(counts.keys(), counts.values(), color='lightgreen')\n",
    "    ax.set_title(tomogram)\n",
    "    ax.set_xlabel(\"Prot√©ine\")\n",
    "    ax.set_ylabel(\"Nombre d'exemplaires\")\n",
    "    # Rotation des √©tiquettes pour une meilleure lisibilit√©\n",
    "    ax.tick_params(axis='x', labelrotation=45, labelsize=8)\n",
    "\n",
    "# Supprimer les sous-graphes vides s'il y en a\n",
    "total_plots = rows * cols\n",
    "if num_tomograms < total_plots:\n",
    "    for idx in range(num_tomograms, total_plots):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        fig.delaxes(axes[row][col])\n",
    "\n",
    "plt.suptitle(\"Histogrammes par tomogramme du nombre d'exemplaires de prot√©ines\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import json\n",
    "\n",
    "def prepare_dataset(image_path, target_path):\n",
    "    \"\"\"\n",
    "    Pr√©pare un dataset associant les donn√©es d'images aux targets (prot√©ines et positions).\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Chemin vers le dossier contenant les images Zarr.\n",
    "        target_path (str): Chemin vers le dossier contenant les targets (fichiers JSON).\n",
    "\n",
    "    Returns:\n",
    "        list: Liste de dictionnaires, o√π chaque √©l√©ment contient les donn√©es d'un tomogramme :\n",
    "            - \"name\": Nom du tomogramme.\n",
    "            - \"images\": Liste des r√©solutions (volumes 3D).\n",
    "            - \"targets\": Dictionnaire {type_mol√©cule: [positions (x, y, z)]}.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "\n",
    "    # Parcourir les tomogrammes dans le dossier des images\n",
    "    for tomogram_name in os.listdir(image_path):\n",
    "        tomogram_image_path = os.path.join(image_path, tomogram_name, \"VoxelSpacing10.000/denoised.zarr\")\n",
    "        tomogram_target_path = os.path.join(target_path, tomogram_name, \"Picks\")\n",
    "\n",
    "        # V√©rifier que les donn√©es Zarr et les targets existent\n",
    "        if not os.path.exists(tomogram_image_path):\n",
    "            print(f\"Images non trouv√©es pour {tomogram_name}, ignor√©.\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(tomogram_target_path):\n",
    "            print(f\"Targets non trouv√©s pour {tomogram_name}, ignor√©.\")\n",
    "            continue\n",
    "\n",
    "        # Charger les images (volumes 3D √† plusieurs r√©solutions)\n",
    "        zgroup = zarr.open_group(tomogram_image_path, mode='r')\n",
    "        sorted_keys = sorted(zgroup.keys(), key=lambda k: np.prod(zgroup[k].shape), reverse=True)\n",
    "        images = [zgroup[key][:] for key in sorted_keys]\n",
    "\n",
    "        # Charger les targets (localisations des particules)\n",
    "        targets = {}\n",
    "        for json_file in os.listdir(tomogram_target_path):\n",
    "            if json_file.endswith(\".json\"):\n",
    "                json_path = os.path.join(tomogram_target_path, json_file)\n",
    "                with open(json_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    molecule_name = data.get(\"pickable_object_name\", \"unknown\")\n",
    "                    points = [\n",
    "                        [point[\"location\"][\"x\"], point[\"location\"][\"y\"], point[\"location\"][\"z\"]]\n",
    "                        for point in data[\"points\"]\n",
    "                    ]\n",
    "                    if molecule_name not in targets:\n",
    "                        targets[molecule_name] = []\n",
    "                    targets[molecule_name].extend(points)\n",
    "\n",
    "        # Ajouter les donn√©es du tomogramme au dataset\n",
    "        dataset.append({\n",
    "            \"name\": tomogram_name,\n",
    "            \"images\": images,  # Liste des r√©solutions\n",
    "            \"targets\": targets  # Localisations des particules par type\n",
    "        })\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# print tomogram shapes for each resolution in the order of the dataset\n",
    "def print_shapes(dataset):\n",
    "    for tomogram in dataset:\n",
    "        print(f\"Tomogramme {tomogram['name']}:\")\n",
    "        for i, image in enumerate(tomogram['images']):\n",
    "            print(f\"  - R√©solution {i}: {image.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins des donn√©es\n",
    "\n",
    "# Pr√©parer le dataset\n",
    "dataset = prepare_dataset(DATA_DIR, TARGET_DIR)\n",
    "\n",
    "print_shapes(dataset)\n",
    "\n",
    "# Exemple : Afficher les donn√©es du premier tomogramme\n",
    "print(f\"Nom du tomogramme : {dataset[0]['name']}\")\n",
    "print(f\"Forme de l'image (r√©solution 1) : {dataset[0]['images'][0].shape}\")\n",
    "print(f\"Targets : {dataset[0]['targets']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# On suppose que les dictionnaires all_data et all_targets ont √©t√© g√©n√©r√©s par vos fonctions process_experiment_runs et load_targets.\n",
    "# Par exemple :\n",
    "#   all_data = process_experiment_runs(DATA_DIR)\n",
    "#   all_targets = load_targets(TARGET_DIR)\n",
    "\n",
    "voxel_size = 10  # M√™me valeur utilis√©e lors du chargement et de l'analyse\n",
    "\n",
    "# Choisir un tomogramme et une r√©solution (ici, 'TS_5_4' et le groupe '0' pour la pleine r√©solution)\n",
    "tomogram_folder = 'TS_5_4'\n",
    "resolution_group = '0'\n",
    "slice_index = 90  # Coupe √† afficher sur l'axe Z\n",
    "\n",
    "# Charger la coupe du tomogramme\n",
    "tomogram_volume = all_data[tomogram_folder][resolution_group]['data']\n",
    "image_slice = tomogram_volume[slice_index, :, :]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image_slice, cmap='gray')\n",
    "plt.title(f\"Tomogramme {tomogram_folder} - Coupe Z={slice_index}\")\n",
    "\n",
    "# V√©rifier si des cibles (targets) sont pr√©sentes pour ce tomogramme\n",
    "if tomogram_folder in all_targets:\n",
    "    molecules = all_targets[tomogram_folder]\n",
    "    \n",
    "    # Pour √©viter les doublons dans la l√©gende\n",
    "    legend_entries = {}\n",
    "    \n",
    "    for molecule, points in molecules.items():\n",
    "        for point in points:\n",
    "            # Extraction des coordonn√©es depuis la cl√© \"location\"\n",
    "            x = point[\"location\"][\"x\"] / voxel_size\n",
    "            y = point[\"location\"][\"y\"] / voxel_size\n",
    "            z = point[\"location\"][\"z\"] / voxel_size  # Coordonn√©e Z en voxels\n",
    "            \n",
    "            # N'afficher que les points proches de la coupe s√©lectionn√©e\n",
    "            if abs(z - slice_index) < 3:  # Seuil ajustable selon la pr√©cision d√©sir√©e\n",
    "                sc = plt.scatter(x, y, s=20)\n",
    "                if molecule not in legend_entries:\n",
    "                    legend_entries[molecule] = sc\n",
    "\n",
    "    if legend_entries:\n",
    "        plt.legend(legend_entries.values(), legend_entries.keys(), loc='upper right')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same with napari\n",
    "\n",
    "colors = {\n",
    "    \"apo-ferritin\": 'red',\n",
    "    \"beta-amylase\": 'green',\n",
    "    \"beta-galactosidase\": 'blue',\n",
    "    \"ribosome\": 'orange',\n",
    "    \"thyroglobulin\": 'purple',\n",
    "    \"virus-like-particle\": 'cyan',\n",
    "    # Vous pouvez ajouter d'autres mol√©cules si n√©cessaire.\n",
    "}\n",
    "\n",
    "import napari\n",
    "\n",
    "# Choisir un tomogramme et une r√©solution (ici, 'TS_5_4' et le groupe '0' pour la pleine r√©solution)\n",
    "tomogram_folder = 'TS_5_4'\n",
    "resolution_group = '0'\n",
    "\n",
    "# Charger le volume du tomogramme\n",
    "tomogram_volume = all_data[tomogram_folder][resolution_group]['data']\n",
    "\n",
    "# Cr√©er une nouvelle instance Napari\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Ajouter le volume du tomogramme\n",
    "viewer.add_image(tomogram_volume, name=tomogram_folder)\n",
    "\n",
    "# Ajouter les cibles (targets) si elles existent\n",
    "if tomogram_folder in all_targets:\n",
    "    molecules = all_targets[tomogram_folder]\n",
    "    print(f\"Chargement des cibles pour {tomogram_folder}...\")\n",
    "    print('Il y a', len(molecules), 'mol√©cules')\n",
    "    \n",
    "    for molecule, points in molecules.items():\n",
    "        print(f\"  * {molecule}: {len(points)} points\")\n",
    "        points_array = np.array([\n",
    "            [point[\"location\"][\"z\"], point[\"location\"][\"y\"], point[\"location\"][\"x\"]]  # Permuter les axes X et Z\n",
    "            for point in points\n",
    "        ]) / voxel_size\n",
    "\n",
    "        print(\"Shape du tomogramme:\", tomogram_volume.shape)\n",
    "        print(\"Min des points:\", points_array.min(axis=0))\n",
    "        print(\"Max des points:\", points_array.max(axis=0))\n",
    "\n",
    "        print(\"Il y a\", len(points_array), \"points\")\n",
    "        print(\"Premier point:\", points_array[0])\n",
    "        \n",
    "\n",
    "        # Ajouter les points √† la visualisation (petite sph√®re pour chaque point)\n",
    "        viewer.add_points(points_array, name=molecule, size=13, face_color=colors.get(molecule, 'white'))\n",
    "        \n",
    "    # v√©rifier l'origine des axes (en haut √† gauche dans napari)\n",
    "    viewer.add_points(np.array([[0, 0, 0]]), name='origine', size=13, face_color='yellow')\n",
    "\n",
    "\n",
    "\n",
    "# run the viewer\n",
    "viewer.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# On suppose que les dictionnaires all_data et all_targets ont √©t√© g√©n√©r√©s par vos fonctions process_experiment_runs et load_targets.\n",
    "# Par exemple :\n",
    "#   all_data = process_experiment_runs(DATA_DIR)\n",
    "#   all_targets = load_targets(TARGET_DIR)\n",
    "\n",
    "# Pour la r√©solution 2, le voxel_size est 4 fois celui de la r√©solution 0 (4 * 10 = 40)\n",
    "voxel_size = 40  \n",
    "tomogram_folder = 'TS_5_4'\n",
    "resolution_group = '2'\n",
    "slice_index = 23  # Choix d'une slice au milieu du volume de r√©solution 2 (le volume a 46 slices)\n",
    "\n",
    "# Charger la coupe du tomogramme √† la r√©solution 2\n",
    "tomogram_volume = all_data[tomogram_folder][resolution_group]['data']\n",
    "image_slice = tomogram_volume[slice_index, :, :]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image_slice, cmap='gray')\n",
    "plt.title(f\"Tomogramme {tomogram_folder} - R√©solution 2 - Slice Z={slice_index}\")\n",
    "\n",
    "# V√©rifier si des cibles (targets) sont pr√©sentes pour ce tomogramme\n",
    "if tomogram_folder in all_targets:\n",
    "    molecules = all_targets[tomogram_folder]\n",
    "    \n",
    "    # Pour √©viter les doublons dans la l√©gende\n",
    "    legend_entries = {}\n",
    "    \n",
    "    for molecule, points in molecules.items():\n",
    "        for point in points:\n",
    "            # Conversion des coordonn√©es physiques en indices voxels en divisant par voxel_size (40 √† cette r√©solution)\n",
    "            x = point[\"location\"][\"x\"] / voxel_size\n",
    "            y = point[\"location\"][\"y\"] / voxel_size\n",
    "            z = point[\"location\"][\"z\"] / voxel_size  # Coordonn√©e Z en voxels\n",
    "            \n",
    "            # Afficher uniquement les points proches de la slice s√©lectionn√©e\n",
    "            if abs(z - slice_index) < 0.75:\n",
    "                sc = plt.scatter(x, y, s=20)\n",
    "                if molecule not in legend_entries:\n",
    "                    legend_entries[molecule] = sc\n",
    "\n",
    "    if legend_entries:\n",
    "        plt.legend(legend_entries.values(), legend_entries.keys(), loc='upper right')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PARTIE 2 : PR√âPARATION DES PATCHES ET DES MASQUES DE SEGMENTATION ---\n",
    "import tensorflow as tf\n",
    "voxel_size = 10  # M√™me valeur utilis√©e pr√©c√©demment\n",
    "\n",
    "# Mapping des mol√©cules aux indices de classes.\n",
    "# La classe 0 sera r√©serv√©e au fond.\n",
    "class_mapping = {\n",
    "    \"background\": 0,\n",
    "    \"apo-ferritin\": 1,\n",
    "    \"beta-amylase\": 2,\n",
    "    \"ribosome\": 3,\n",
    "    \"thyroglobulin\": 4,\n",
    "    \"virus-like-particle\": 5,\n",
    "    \"beta-galactosidase\": 6\n",
    "    # Vous pouvez ajouter d'autres mol√©cules si n√©cessaire.\n",
    "}\n",
    "\n",
    "def generate_mask(volume_shape, targets, voxel_size, class_mapping, sphere_radius=2):\n",
    "    \"\"\"\n",
    "    Cr√©e un masque de segmentation (de dimensions volume_shape) √† partir des targets.\n",
    "    Pour chaque point, on convertit la position physique en indice voxel et on dessine\n",
    "    une petite sph√®re (de rayon sphere_radius voxels) avec la classe correspondante.\n",
    "    \n",
    "    Args:\n",
    "        volume_shape (tuple): Dimensions du volume (Z, Y, X).\n",
    "        targets (dict): Dictionnaire des targets avec pour chaque mol√©cule une liste de points.\n",
    "        voxel_size (float): Facteur de conversion des coordonn√©es physiques en indices voxels.\n",
    "        class_mapping (dict): Mapping de la mol√©cule vers l'indice de classe (0 pour le fond, >0 pour les particules).\n",
    "        sphere_radius (int): Rayon de la sph√®re (en voxels) √† dessiner autour de chaque point.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Masque de segmentation de dimensions volume_shape.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(volume_shape, dtype=np.uint8)  # Fond = 0\n",
    "    for molecule, points in targets.items():\n",
    "        if molecule not in class_mapping:\n",
    "            continue\n",
    "        class_idx = class_mapping[molecule]\n",
    "        for point in points:\n",
    "            # Si le point est un dictionnaire avec la cl√© \"location\", on l'utilise\n",
    "            if isinstance(point, dict) and \"location\" in point:\n",
    "                x_coord = point[\"location\"][\"x\"]\n",
    "                y_coord = point[\"location\"][\"y\"]\n",
    "                z_coord = point[\"location\"][\"z\"]\n",
    "            else:\n",
    "                # Sinon, on suppose que le point est une liste/tuple de coordonn√©es [x, y, z]\n",
    "                x_coord, y_coord, z_coord = point\n",
    "            \n",
    "            x_center = int(round(x_coord / voxel_size))\n",
    "            y_center = int(round(y_coord / voxel_size))\n",
    "            z_center = int(round(z_coord / voxel_size))\n",
    "            \n",
    "            # Dessiner une petite sph√®re autour du point\n",
    "            for dz in range(-sphere_radius, sphere_radius + 1):\n",
    "                for dy in range(-sphere_radius, sphere_radius + 1):\n",
    "                    for dx in range(-sphere_radius, sphere_radius + 1):\n",
    "                        if dx**2 + dy**2 + dz**2 <= sphere_radius**2:\n",
    "                            z_idx = z_center + dz\n",
    "                            y_idx = y_center + dy\n",
    "                            x_idx = x_center + dx\n",
    "                            if (0 <= z_idx < volume_shape[0] and\n",
    "                                0 <= y_idx < volume_shape[1] and\n",
    "                                0 <= x_idx < volume_shape[2]):\n",
    "                                mask[z_idx, y_idx, x_idx] = class_idx\n",
    "    return mask\n",
    "\n",
    "def extract_grid_patches(volume, mask, num_cubes_axis):\n",
    "    \"\"\"\n",
    "    Extrait tous les patches qui couvrent enti√®rement le volume en divisant chaque dimension en num_cubes_axis segments.\n",
    "    On suppose que le volume est exactement divisible par num_cubes_axis sur chaque axe.\n",
    "    \n",
    "    Args:\n",
    "        volume (ndarray): Volume 3D d'entr√©e, de forme (Z, Y, X).\n",
    "        mask (ndarray): Masque associ√©, de m√™me forme.\n",
    "        num_cubes_axis (int): Nombre de segments (patchs) par axe (exemple : 4 donnera 4x4x4 = 64 patches).\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (patches_img, patches_mask) \n",
    "               - patches_img : liste de patches d'image.\n",
    "               - patches_mask : liste de patches de masque.\n",
    "    \"\"\"\n",
    "    z_dim, y_dim, x_dim = volume.shape\n",
    "    patch_size_z = z_dim // num_cubes_axis\n",
    "    patch_size_y = y_dim // num_cubes_axis\n",
    "    patch_size_x = x_dim // num_cubes_axis\n",
    "    \n",
    "    patches_img = []\n",
    "    patches_mask = []\n",
    "    \n",
    "    for i in range(num_cubes_axis):\n",
    "        for j in range(num_cubes_axis):\n",
    "            for k in range(num_cubes_axis):\n",
    "                z0 = i * patch_size_z\n",
    "                y0 = j * patch_size_y\n",
    "                x0 = k * patch_size_x\n",
    "                patch_img = volume[z0:z0+patch_size_z, y0:y0+patch_size_y, x0:x0+patch_size_x]\n",
    "                patch_mask = mask[z0:z0+patch_size_z, y0:y0+patch_size_y, x0:x0+patch_size_x]\n",
    "                patches_img.append(patch_img)\n",
    "                patches_mask.append(patch_mask)\n",
    "    \n",
    "    return patches_img, patches_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "Y_train_list = []\n",
    "\n",
    "# Ici, num_cubes_axis doit √™tre choisi de fa√ßon √† diviser exactement les dimensions du volume.\n",
    "# Par exemple, pour le volume (184, 630, 630), on pourra choisir num_cubes_axis = 2 ou 4\n",
    "# si les dimensions sont exactement divisibles par ce nombre.\n",
    "num_cubes_axis = 2  # Exemple : divise le volume en 2x2x2 = 8 patches\n",
    "\n",
    "for tomogram in dataset:\n",
    "    volume = tomogram[\"images\"][2]  # Utilisation de la r√©solution la plus fine\n",
    "    mask_full = generate_mask(volume.shape, tomogram[\"targets\"], voxel_size, class_mapping)\n",
    "    print(f\"Tomogramme {tomogram['name']} volume: {volume.shape}, masque: {mask_full.shape}\")\n",
    "    \n",
    "    patches_img, patches_mask = extract_grid_patches(volume, mask_full, num_cubes_axis)\n",
    "    \n",
    "    for patch_img, patch_mask in zip(patches_img, patches_mask):\n",
    "         # On ajoute la dimension de canal √† l'image patch (le mod√®le attend (patch_size_z, patch_size_y, patch_size_x, 1))\n",
    "         patch_img = patch_img[..., np.newaxis]\n",
    "         X_train_list.append(patch_img)\n",
    "         Y_train_list.append(patch_mask)\n",
    "\n",
    "X_train = np.array(X_train_list, dtype=np.float32)\n",
    "Y_train_int = np.array(Y_train_list, dtype=np.uint8)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train_int shape:\", Y_train_int.shape)\n",
    "\n",
    "# Conversion du masque en encodage one-hot (le mod√®le attend n_classes canaux en sortie)\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train_int, num_classes=7)\n",
    "print(\"Y_train shape (one-hot):\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import necessary libraries since execution state was reset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload Y_train_int if available\n",
    "# Assuming Y_train_int is available after the reset\n",
    "# If not, you may need to redefine and reload the dataset\n",
    "\n",
    "# Determine the presence of proteins in each patch (binary: 0 = background, 1 = contains proteins)\n",
    "patch_contains_protein = (Y_train_int > 0).any(axis=(1, 2, 3))\n",
    "\n",
    "# Compute proportions\n",
    "num_patches = len(Y_train_int)\n",
    "num_with_proteins = np.sum(patch_contains_protein)\n",
    "num_without_proteins = num_patches - num_with_proteins\n",
    "\n",
    "# Display as a pie chart\n",
    "labels = [\"Avec Prot√©ines\", \"Sans Prot√©ines\"]\n",
    "sizes = [num_with_proteins, num_without_proteins]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['skyblue', 'lightcoral'], startangle=90)\n",
    "plt.title(\"Proportion des Patches Contenant des Prot√©ines\")\n",
    "plt.show()\n",
    "\n",
    "# Display numerical results\n",
    "num_with_proteins, num_without_proteins, num_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# D√©terminer les patchs qui contiennent des prot√©ines (au moins un voxel avec une valeur > 0)\n",
    "patch_contains_protein = (Y_train_int > 0).any(axis=(1, 2, 3))\n",
    "\n",
    "# S√©parer les indices des patchs avec et sans prot√©ines\n",
    "indices_with_protein = np.where(patch_contains_protein)[0]\n",
    "indices_without_protein = np.where(~patch_contains_protein)[0]\n",
    "\n",
    "# D√©terminer combien de patchs sans prot√©ines nous devons garder pour √©quilibrer √† 50/50\n",
    "num_with_protein = len(indices_with_protein)\n",
    "num_without_protein_needed = num_with_protein  # Pour obtenir un √©quilibre 50/50\n",
    "\n",
    "# √âchantillonner al√©atoirement les patchs sans prot√©ines pour atteindre l'√©quilibre\n",
    "indices_without_protein_sampled = np.random.choice(indices_without_protein, num_without_protein_needed, replace=False)\n",
    "\n",
    "# Concat√©ner les indices des patchs s√©lectionn√©s\n",
    "balanced_indices = np.concatenate([indices_with_protein, indices_without_protein_sampled])\n",
    "\n",
    "# M√©langer les indices pour √©viter tout biais d'ordre\n",
    "np.random.shuffle(balanced_indices)\n",
    "\n",
    "# Construire les nouveaux ensembles X_train et Y_train √©quilibr√©s\n",
    "X_train_balanced = X_train[balanced_indices]\n",
    "Y_train_int_balanced = Y_train_int[balanced_indices]\n",
    "\n",
    "# Conversion du masque en encodage one-hot (le mod√®le attend n_classes canaux en sortie)\n",
    "Y_train_balanced = tf.keras.utils.to_categorical(Y_train_int_balanced, num_classes=7)\n",
    "\n",
    "# V√©rifier les nouvelles proportions\n",
    "num_patches_balanced = len(Y_train_int_balanced)\n",
    "num_with_proteins_balanced = np.sum((Y_train_int_balanced > 0).any(axis=(1, 2, 3)))\n",
    "num_without_proteins_balanced = num_patches_balanced - num_with_proteins_balanced\n",
    "\n",
    "# Affichage des proportions sous forme de camembert\n",
    "labels = [\"Avec Prot√©ines\", \"Sans Prot√©ines\"]\n",
    "sizes = [num_with_proteins_balanced, num_without_proteins_balanced]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['skyblue', 'lightcoral'], startangle=90)\n",
    "plt.title(\"Proportion des Patches Contenant des Prot√©ines (√âquilibr√©)\")\n",
    "plt.show()\n",
    "\n",
    "# Affichage des proportions des classes (prot√©ines sp√©cifiques)\n",
    "unique_classes, counts = np.unique(Y_train_int_balanced[Y_train_int_balanced > 0], return_counts=True)\n",
    "\n",
    "# Mapping des classes vers les noms de prot√©ines\n",
    "class_labels = {\n",
    "    0: \"background\",\n",
    "    1: \"apo-ferritin\",\n",
    "    2: \"beta-amylase\",\n",
    "    3: \"beta-galactosidase\",\n",
    "    4: \"ribosome\",\n",
    "    5: \"thyroglobulin\",\n",
    "    6: \"virus-like-particle\",\n",
    "    7: \"beta-galactosidase\"\n",
    "}\n",
    "\n",
    "# Convertir indices de classes en noms\n",
    "labels = [class_labels.get(int(cls), f\"Classe {cls}\") for cls in unique_classes]\n",
    "sizes = counts\n",
    "\n",
    "# Affichage des proportions des prot√©ines sous forme de camembert\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['red', 'blue', 'green', 'purple', 'orange', 'cyan'], startangle=140)\n",
    "plt.title(\"Proportion de chaque prot√©ine dans le dataset √©quilibr√©\")\n",
    "plt.show()\n",
    "\n",
    "# Afficher les tailles finales\n",
    "X_train_balanced.shape, Y_train_balanced.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def display_tomogram_and_target(all_data, all_targets, tomogram_folder, resolution_group, slice_index, voxel_size, class_mapping, sphere_radius=2):\n",
    "    \"\"\"\n",
    "    Affiche c√¥te √† c√¥te la coupe du tomogramme et le masque target associ√©.\n",
    "    \"\"\"\n",
    "    # Charger le volume et extraire la coupe\n",
    "    volume = all_data[tomogram_folder][resolution_group]['data']\n",
    "    image_slice = volume[slice_index, :, :]\n",
    "    \n",
    "    # G√©n√©rer le masque complet √† partir des targets\n",
    "    mask_full = generate_mask(volume.shape, all_targets.get(tomogram_folder, {}), voxel_size, class_mapping, sphere_radius)\n",
    "    target_slice = mask_full[slice_index, :, :]\n",
    "\n",
    "    # Cr√©ation de la figure avec deux sous-graphes\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    # Palette de couleurs fixe pour chaque mol√©cule\n",
    "    colors = {\n",
    "        \"apo-ferritin\": \"red\",\n",
    "        \"beta-amylase\": \"blue\",\n",
    "        \"ribosome\": \"purple\",\n",
    "        \"thyroglobulin\": \"orange\",\n",
    "        \"virus-like-particle\": \"cyan\",\n",
    "        \"beta-galactosidase\": \"green\"\n",
    "    }\n",
    "    \n",
    "    # --- Affichage de la coupe du tomogramme avec les targets ---\n",
    "    axs[0].imshow(image_slice, cmap='gray')\n",
    "    axs[0].set_title(f\"Tomogramme {tomogram_folder} - Slice Z={slice_index}\")\n",
    "\n",
    "    legend_entries = {}\n",
    "    targets = all_targets.get(tomogram_folder, {})\n",
    "\n",
    "    for molecule, points in targets.items():\n",
    "        color = colors.get(molecule, \"yellow\")  # Assurer une couleur par d√©faut si inconnue\n",
    "        for point in points:\n",
    "            x = point[\"location\"][\"x\"] / voxel_size\n",
    "            y = point[\"location\"][\"y\"] / voxel_size\n",
    "            z = point[\"location\"][\"z\"] / voxel_size\n",
    "            if abs(z - slice_index) < 1:\n",
    "                sc = axs[0].scatter(x, y, s=50, edgecolors=color, facecolors='none', linewidths=1.5)\n",
    "                if molecule not in legend_entries:\n",
    "                    legend_entries[molecule] = sc\n",
    "\n",
    "    if legend_entries:\n",
    "        axs[0].legend(legend_entries.values(), legend_entries.keys(), loc='upper right')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # --- Affichage du masque g√©n√©r√© ---\n",
    "    axs[1].imshow(target_slice, cmap='jet')\n",
    "    axs[1].set_title(f\"Masque Target {tomogram_folder} - Slice Z={slice_index}\")\n",
    "\n",
    "    legend_entries_mask = {}\n",
    "    for molecule, points in targets.items():\n",
    "        color = colors.get(molecule, \"yellow\")\n",
    "        for point in points:\n",
    "            x = point[\"location\"][\"x\"] / voxel_size\n",
    "            y = point[\"location\"][\"y\"] / voxel_size\n",
    "            z = point[\"location\"][\"z\"] / voxel_size\n",
    "            if abs(z - slice_index) < 1:\n",
    "                sc = axs[1].scatter(x, y, s=20, edgecolors=color, facecolors='none', linewidths=1.5)\n",
    "                if molecule not in legend_entries_mask:\n",
    "                    legend_entries_mask[molecule] = sc\n",
    "\n",
    "    if legend_entries_mask:\n",
    "        axs[1].legend(legend_entries_mask.values(), legend_entries_mask.keys(), loc='upper right')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Exemple d'utilisation ---\n",
    "# On suppose que all_data et all_targets ont √©t√© g√©n√©r√©s pr√©c√©demment,\n",
    "# et que class_mapping est d√©fini (comme dans l'exemple fourni).\n",
    "voxel_size = 40\n",
    "tomogram_folder = 'TS_5_4'\n",
    "resolution_group = '2'\n",
    "slice_index = 23\n",
    "\n",
    "display_tomogram_and_target(all_data, all_targets, tomogram_folder, resolution_group, slice_index, voxel_size, class_mapping, sphere_radius=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_balanced.shape)\n",
    "print(Y_train_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Afficher les valeurs uniques pr√©sentes dans Y_train (donn√©es segment√©es)\n",
    "unique_values = np.unique(Y_train_int)  # Y_train_int est la version non one-hot de Y_train\n",
    "\n",
    "unique_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Y_train contient NaN ?\", np.isnan(Y_train).any())\n",
    "print(\"X_train contient NaN ?\", np.isnan(X_train).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protein_accuracy(y_true, y_pred):\n",
    "    y_true_labels = tf.argmax(y_true, axis=-1)\n",
    "    y_pred_labels = tf.argmax(y_pred, axis=-1)\n",
    "    mask = tf.not_equal(y_true_labels, 0)\n",
    "    correct = tf.equal(y_true_labels, y_pred_labels)\n",
    "    correct_masked = tf.boolean_mask(correct, mask)\n",
    "    \n",
    "    # Si aucun voxel de prot√©ine n'est pr√©sent, retourner 0 pour √©viter NaN.\n",
    "    return tf.cond(tf.equal(tf.size(correct_masked), 0),\n",
    "                   lambda: tf.constant(0.0, dtype=tf.float32),\n",
    "                   lambda: tf.reduce_mean(tf.cast(correct_masked, tf.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Cropping3D, Concatenate, Dropout, BatchNormalization, Activation, ZeroPadding3D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "\n",
    "\n",
    "# Vos poids de classe pour les prot√©ines (les cl√©s correspondent aux noms de mol√©cules)\n",
    "protein_weights = {\n",
    "    'background': 0.5,\n",
    "    'apo-ferritin': 1,\n",
    "    'beta-amylase': 0.01,\n",
    "    'beta-galactosidase': 2,\n",
    "    'ribosome': 1,\n",
    "    'thyroglobulin': 2,\n",
    "    'virus-like-particle': 1,\n",
    "}\n",
    "\n",
    "# Mapping des mol√©cules vers leurs indices (classe 0 = fond)\n",
    "class_mapping = {\n",
    "    \"background\": 0,\n",
    "    \"apo-ferritin\": 1,\n",
    "    \"beta-amylase\": 2,\n",
    "    \"ribosome\": 3,\n",
    "    \"thyroglobulin\": 4,\n",
    "    \"virus-like-particle\": 5,\n",
    "    \"beta-galactosidase\": 6\n",
    "}\n",
    "# On suppose ici que le nombre total de classes (background + prot√©ines) est 7.\n",
    "n_classes = 7\n",
    "\n",
    "\n",
    "@register_keras_serializable()\n",
    "def weighted_categorical_crossentropy(weights_dict, class_mapping, num_classes):\n",
    "    \"\"\"\n",
    "    Fonction de perte pond√©r√©e qui ignore le fond (classe 0).\n",
    "    \"\"\"\n",
    "    weight_vector = np.ones(num_classes, dtype=np.float32)\n",
    "    for molecule, class_idx in class_mapping.items():\n",
    "        if molecule in weights_dict:\n",
    "            weight_vector[class_idx] = weights_dict[molecule]\n",
    "    weight_vector = tf.constant(weight_vector, dtype=tf.float32)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0)\n",
    "        loss_unweighted = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "\n",
    "        # Exclure les voxels de classe 0 (fond)\n",
    "        true_class = tf.argmax(y_true, axis=-1)\n",
    "        mask = tf.not_equal(true_class, 0)\n",
    "        voxel_weights = tf.gather(weight_vector, true_class)\n",
    "        weighted_loss = loss_unweighted * voxel_weights\n",
    "\n",
    "        # Appliquer le masque : ne consid√©rer que les prot√©ines\n",
    "        masked_loss = tf.boolean_mask(weighted_loss, mask)\n",
    "\n",
    "        return tf.cond(\n",
    "            tf.greater(tf.size(masked_loss), 0),  \n",
    "            lambda: tf.reduce_mean(masked_loss),  \n",
    "            lambda: tf.constant(0.0, dtype=tf.float32)\n",
    "        )\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def conv_block(inputs, n_filters, dropout=0, batch_norm=True):\n",
    "    x = Conv3D(n_filters, kernel_size=3, padding='same')(inputs)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv3D(n_filters, kernel_size=3, padding='same')(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if dropout > 0:\n",
    "        x = Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def unet3d_model(input_shape, n_classes, filters=[16, 32, 64], dropout=0):\n",
    "    inputs = Input(input_shape)\n",
    "    # Encoder\n",
    "    c1 = conv_block(inputs, filters[0], dropout)\n",
    "    p1 = MaxPooling3D(pool_size=(2,2,2), padding=\"same\")(c1)\n",
    "    \n",
    "    c2 = conv_block(p1, filters[1], dropout)\n",
    "    p2 = MaxPooling3D(pool_size=(2,2,2), padding=\"same\")(c2)\n",
    "    \n",
    "    c3 = conv_block(p2, filters[2], dropout)\n",
    "    p3 = MaxPooling3D(pool_size=(2,2,2), padding=\"same\")(c3)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c4 = conv_block(p3, filters[2]*2, dropout)\n",
    "    # Decoder\n",
    "    u3 = UpSampling3D(size=(2,2,2))(c4)\n",
    "    # Ici, c3 a √©t√© obtenu avec padding=\"same\". On s'attend √† ce que u3 et c3 aient les m√™mes dimensions.\n",
    "    u3 = Concatenate()([u3, c3])\n",
    "    c5 = conv_block(u3, filters[2], dropout)\n",
    "    \n",
    "    u2 = UpSampling3D(size=(2,2,2))(c5)\n",
    "    u2 = Concatenate()([u2, c2])\n",
    "    c6 = conv_block(u2, filters[1], dropout)\n",
    "    \n",
    "    u1 = UpSampling3D(size=(2,2,2))(c6)\n",
    "    # On remarque que la dimension spatiale de u1 est calcul√©e par multiplication par 2,\n",
    "    # ce qui peut donner une taille l√©g√®rement diff√©rente de celle de c1.\n",
    "    # Par exemple, avec une entr√©e de (23,79,79), u1 pourrait avoir (24,80,80).\n",
    "    # On applique alors un ZeroPadding3D sur c1 pour l'ajuster.\n",
    "    c1_pad = ZeroPadding3D(padding=((0,1), (0,1), (0,1)))(c1)\n",
    "    u1 = Concatenate()([u1, c1_pad])\n",
    "    c7 = conv_block(u1, filters[0], dropout)\n",
    "\n",
    "\n",
    "    # Cropping pour ajuster la taille finale\n",
    "    output_crop = Cropping3D(cropping=((0,1), (0,1), (0,1)))(c7)\n",
    "    outputs = Conv3D(n_classes, kernel_size=1, activation='softmax')(output_crop)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Param√®tres d'entr√©e adapt√©s √† votre cas (par exemple, avec des patches de r√©solution 2)\n",
    "input_shape = (23, 79, 79, 1)\n",
    "n_classes = 7\n",
    "filters = [16, 32, 64]\n",
    "dropout = 0\n",
    "\n",
    "loss_fn = weighted_categorical_crossentropy(protein_weights, class_mapping, n_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet3d_model(input_shape, n_classes, filters, dropout)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy', protein_accuracy])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Ensuite, vous pouvez lancer l'entra√Ænement comme pr√©c√©demment :\n",
    "history = model.fit(X_train, Y_train, batch_size=1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du mod√®le entra√Æn√© (mod√®le complet, y compris l'architecture, les poids et les param√®tres d'optimisation et fonction de perte)\n",
    "model.save('unet3d_trained_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red√©finir la fonction de perte pour l'utiliser dans le chargement du mod√®le\n",
    "loss_fn = weighted_categorical_crossentropy(protein_weights, class_mapping, n_classes)\n",
    "\n",
    "# Charger le mod√®le avec la bonne fonction de perte et la m√©trique personnalis√©e\n",
    "model = tf.keras.models.load_model(\n",
    "    \"unet3d_trained_model.keras\",\n",
    "    custom_objects={\n",
    "        \"protein_accuracy\": protein_accuracy,\n",
    "        \"loss\": loss_fn\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# V√©rifier que le mod√®le est bien charg√©\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lectionner un patch au hasard dans X_test\n",
    "index = np.random.randint(0, len(X_test))\n",
    "\n",
    "# Sauvegarde du mod√®le entra√Æn√©\n",
    "model.save('unet3d_trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# üîπ **Palette de couleurs pour les prot√©ines**\n",
    "colors = {\n",
    "    0: \"gray\",\n",
    "    1: \"red\",\n",
    "    2: \"blue\",\n",
    "    3: \"green\",\n",
    "    4: \"purple\",\n",
    "    5: \"orange\",\n",
    "    6: \"cyan\",\n",
    "}\n",
    "\n",
    "# üîπ **Mapping des classes vers les noms des prot√©ines**\n",
    "class_labels = {\n",
    "    0: \"Fond\",\n",
    "    1: \"apo-ferritin\",\n",
    "    2: \"beta-amylase\",\n",
    "    3: \"ribosome\",\n",
    "    4: \"thyroglobulin\",\n",
    "    5: \"virus-like-particle\",\n",
    "    6: \"beta-galactosidase\"\n",
    "}\n",
    "\n",
    "# S√©lectionner un patch au hasard dans X_train\n",
    "index = np.random.randint(0, len(X_train))\n",
    "\n",
    "# Extraire le patch d'entra√Ænement\n",
    "x_sample = X_train[index]  # (23, 79, 79, 1)\n",
    "y_true = Y_train[index]    # (23, 79, 79, 8) -> One-hot\n",
    "\n",
    "# Ajouter une dimension batch pour la pr√©diction\n",
    "x_sample_expanded = np.expand_dims(x_sample, axis=0)\n",
    "\n",
    "# Effectuer la pr√©diction\n",
    "y_pred = model.predict(x_sample_expanded)\n",
    "\n",
    "# Convertir y_pred en indices de classes (prendre la classe avec la plus haute probabilit√©)\n",
    "y_pred_classes = np.argmax(y_pred[0], axis=-1)  # (23, 79, 79)\n",
    "y_true_classes = np.argmax(y_true, axis=-1)  # (23, 79, 79)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction(x_sample, y_true_classes, y_pred_classes, slice_index=11):\n",
    "    \"\"\"\n",
    "    Affiche une coupe du patch test√©, avec :\n",
    "    - L'image brute (X_test)\n",
    "    - Le masque r√©el (Y_test)\n",
    "    - La pr√©diction du mod√®le (Y_pred)\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Image brute\n",
    "    axs[0].imshow(x_sample[slice_index, :, :, 0], cmap=\"gray\")\n",
    "    axs[0].set_title(f\"Image Brute - Slice Z={slice_index}\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    # Masque de v√©rit√© terrain (Y_test)\n",
    "    axs[1].imshow(y_true_classes[slice_index, :, :], cmap=\"jet\")\n",
    "    axs[1].set_title(f\"Masque V√©rit√© Terrain - Slice Z={slice_index}\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    # Pr√©diction du mod√®le (Y_pred)\n",
    "    axs[2].imshow(y_pred_classes[slice_index, :, :], cmap=\"jet\")\n",
    "    axs[2].set_title(f\"Pr√©diction Mod√®le - Slice Z={slice_index}\")\n",
    "    axs[2].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Afficher les r√©sultats pour une coupe Z donn√©e\n",
    "display_prediction(x_sample, y_true_classes, y_pred_classes, slice_index=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
